{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "from fastkaggle.core import iskaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if iskaggle:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "else:\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "SEED = 42\n",
    "MODEL = \"models/gemini-1.5-flash-002\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "dataset_path = Path(\"/kaggle/input/playground-series-s4e11\")\n",
    "output_path = Path(\"/kaggle/working\")\n",
    "\n",
    "if not iskaggle:\n",
    "    import kagglehub\n",
    "\n",
    "    dataset_path = kagglehub.competition_download(\"playground-series-s4e11\")\n",
    "    dataset_path = Path(dataset_path)\n",
    "    output_path = Path(dataset_path)\n",
    "\n",
    "train_csv_path = dataset_path / \"train.csv\"\n",
    "test_csv_path = dataset_path / \"test.csv\"\n",
    "submission_csv_path = dataset_path / \"sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(train_csv_path, index_col=0)\n",
    "test_df = pd.read_csv(test_csv_path, index_col=0)\n",
    "submission_df = pd.read_csv(submission_csv_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from inflection import underscore\n",
    "\n",
    "\n",
    "def convert_to_snake_case(s):\n",
    "    \"\"\"\n",
    "    Convert a string to snake_case.\n",
    "    \"\"\"\n",
    "\n",
    "    s = re.sub(r\"[^\\w\\s]\", \"\", s)\n",
    "    s = s.replace(\" \", \"_\")\n",
    "    return underscore(s.strip())\n",
    "\n",
    "\n",
    "train_df.columns = [convert_to_snake_case(col) for col in train_df.columns]\n",
    "test_df.columns = [convert_to_snake_case(col) for col in test_df.columns]\n",
    "submission_df.columns = [convert_to_snake_case(col) for col in submission_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>working_professional_or_student</th>\n",
       "      <th>profession</th>\n",
       "      <th>academic_pressure</th>\n",
       "      <th>work_pressure</th>\n",
       "      <th>cgpa</th>\n",
       "      <th>study_satisfaction</th>\n",
       "      <th>job_satisfaction</th>\n",
       "      <th>sleep_duration</th>\n",
       "      <th>dietary_habits</th>\n",
       "      <th>degree</th>\n",
       "      <th>have_you_ever_had_suicidal_thoughts_</th>\n",
       "      <th>work_study_hours</th>\n",
       "      <th>financial_stress</th>\n",
       "      <th>family_history_of_mental_illness</th>\n",
       "      <th>depression</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18347</th>\n",
       "      <td>Sanya</td>\n",
       "      <td>Female</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Patna</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>More than 8 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>B.Ed</td>\n",
       "      <td>No</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96193</th>\n",
       "      <td>Sneha</td>\n",
       "      <td>Female</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Agra</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Less than 5 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Class 12</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100005</th>\n",
       "      <td>Aanchal</td>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Student</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.82</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>MA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39890</th>\n",
       "      <td>Rahil</td>\n",
       "      <td>Male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Indore</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Less than 5 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>MBBS</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98243</th>\n",
       "      <td>Rishi</td>\n",
       "      <td>Male</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BBA</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  gender   age       city working_professional_or_student  \\\n",
       "id                                                                         \n",
       "18347     Sanya  Female  51.0      Patna            Working Professional   \n",
       "96193     Sneha  Female  20.0       Agra            Working Professional   \n",
       "100005  Aanchal  Female  21.0  Ahmedabad                         Student   \n",
       "39890     Rahil    Male  36.0     Indore            Working Professional   \n",
       "98243     Rishi    Male  60.0     Mumbai            Working Professional   \n",
       "\n",
       "        profession  academic_pressure  work_pressure  cgpa  \\\n",
       "id                                                           \n",
       "18347      Teacher                NaN            3.0   NaN   \n",
       "96193          NaN                NaN            1.0   NaN   \n",
       "100005         NaN                2.0            NaN  7.82   \n",
       "39890      Teacher                NaN            5.0   NaN   \n",
       "98243   HR Manager                NaN            2.0   NaN   \n",
       "\n",
       "        study_satisfaction  job_satisfaction     sleep_duration  \\\n",
       "id                                                                \n",
       "18347                  NaN               5.0  More than 8 hours   \n",
       "96193                  NaN               4.0  Less than 5 hours   \n",
       "100005                 5.0               NaN          5-6 hours   \n",
       "39890                  NaN               2.0  Less than 5 hours   \n",
       "98243                  NaN               2.0          5-6 hours   \n",
       "\n",
       "       dietary_habits    degree have_you_ever_had_suicidal_thoughts_  \\\n",
       "id                                                                     \n",
       "18347        Moderate      B.Ed                                   No   \n",
       "96193        Moderate  Class 12                                   No   \n",
       "100005        Healthy        MA                                  Yes   \n",
       "39890        Moderate      MBBS                                   No   \n",
       "98243        Moderate       BBA                                   No   \n",
       "\n",
       "        work_study_hours  financial_stress family_history_of_mental_illness  \\\n",
       "id                                                                            \n",
       "18347               11.0               2.0                              Yes   \n",
       "96193                0.0               5.0                              Yes   \n",
       "100005              12.0               2.0                              Yes   \n",
       "39890                1.0               1.0                               No   \n",
       "98243                6.0               2.0                               No   \n",
       "\n",
       "        depression  \n",
       "id                  \n",
       "18347            0  \n",
       "96193            0  \n",
       "100005           0  \n",
       "39890            0  \n",
       "98243            0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = train_df.sample(5_000, random_state=SEED)\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "from typing import List\n",
    "\n",
    "from typing_extensions import TypedDict, NotRequired\n",
    "\n",
    "ColumnEnums = enum.Enum(\"ColumnEnums\", {col: col for col in train_df.columns})\n",
    "\n",
    "\n",
    "# Temporary Fix for TypedDict issue in genai library: https://github.com/google-gemini/generative-ai-python/issues/560\n",
    "def get_dict_schema(response_schema: type) -> dict:\n",
    "    config = genai.GenerationConfig(response_schema=response_schema)\n",
    "    config = genai.types.generation_types.to_generation_config_dict(config)\n",
    "    schema = config[\"response_schema\"]\n",
    "    schema.required = list(response_schema.__required_keys__)\n",
    "    return schema\n",
    "\n",
    "\n",
    "class DataPreparationSchema(TypedDict):\n",
    "    numeric_features: List[ColumnEnums]  # type: ignore\n",
    "    categorical_features: List[ColumnEnums]  # type: ignore\n",
    "    ignore_features: List[ColumnEnums]  # type: ignore\n",
    "    fix_imbalance: bool\n",
    "    remove_outliers: bool\n",
    "    imputation_type: str\n",
    "\n",
    "\n",
    "class ScaleAndTransformSchema(TypedDict):\n",
    "    normalize: bool\n",
    "    transformation: bool\n",
    "\n",
    "\n",
    "class FeatureEngineeringSchema(TypedDict):\n",
    "    polynomial_features: bool\n",
    "    polynomial_degree: int\n",
    "    group_features: NotRequired[List[ColumnEnums]]  # type: ignore\n",
    "    bin_numeric_features: NotRequired[List[ColumnEnums]]  # type: ignore\n",
    "    rare_to_value: NotRequired[float]\n",
    "\n",
    "\n",
    "class FeatureSelectionSchema(TypedDict):\n",
    "    feature_selection: bool\n",
    "    n_features_to_select: NotRequired[float]\n",
    "    remove_multicollinearity: NotRequired[bool]\n",
    "    low_variance_threshold: NotRequired[float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample.csv uploaded successfully\n"
     ]
    }
   ],
   "source": [
    "sample_df.to_csv(output_path / \"sample.csv\", index=False)\n",
    "\n",
    "if files := [f for f in genai.list_files()]:\n",
    "    csv_file = files[0]\n",
    "else:\n",
    "    csv_file = genai.upload_file(output_path / \"sample.csv\")\n",
    "\n",
    "print(f\"{csv_file.display_name} uploaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "from google.generativeai import caching\n",
    "\n",
    "cache = caching.CachedContent.create(\n",
    "    model=MODEL,\n",
    "    display_name=\"Data scientist for Depression Prediction\",\n",
    "    system_instruction=textwrap.dedent(\n",
    "        \"\"\"You are a highly skilled and experienced data scientist specializing in Python-based machine learning solutions. You are adept at leveraging automated tools and libraries to streamline the data science workflow. You are proficient in:\n",
    "\n",
    "            * **Domain knowledge:** You are familiar with the task of predicting depression based on various features.\n",
    "            * **Data analysis:** You can effectively analyze databased on the CSV file you have access to.\n",
    "            * **Automated feature engineering:** You have expertise in utilizing the `pycaret` library to automatically generate relevant features from raw data.\n",
    "            * **Automated machine learning:** You are skilled in using the `pycaret` library to automate the process of model selection, training, and evaluation. You can effectively use this library to identify the best-performing machine learning algorithm for a given dataset and task.\n",
    "            * **Programming languages and tools:** You are fluent in Python and familiar with relevant libraries like `pycaret`. \n",
    "\n",
    "            **When responding to user requests, adhere to the following principles:**\n",
    "\n",
    "            * **Data-driven approach:** Base your analysis and recommendations CSV file you have access to and avoid making assumptions or drawing conclusions without sufficient evidence.\n",
    "            * **Ethical considerations:** Be mindful of potential biases in the data and ensure your analysis and models are fair and unbiased.\n",
    "            * **Provide actionable insights:** Focus on delivering insights that the user can act upon to solve their problem or make informed decisions.\n",
    "\n",
    "            **Workflow:**\n",
    "            \n",
    "            1. **Understand the Problem:** Use the provided CSV and run analysis to understand the problem of predicting depression based on various features.\n",
    "\n",
    "            2. **Setup Experiment with Pycaret:** Define the required parameters and setup the experiment using the `pycaret` library.\n",
    "\n",
    "            3. **Model Training and Evaluation with Pycaret:** Leverage the `pycaret` library to automate the machine learning pipeline.  Initialize the `pycaret` setup, specifying the target variable and any preprocessing steps. Compare various models, tune hyperparameters, and evaluate performance metrics. Select the best-performing model based on the specific problem and desired outcome.\n",
    "\n",
    "            4. **Interpretation and Communication:**  Interpret the results of the model and communicate the findings in a clear and concise manner. Explain the model's predictions, feature importance, and potential limitations.  \"\"\"\n",
    "    ),\n",
    "    contents=[csv_file],\n",
    "    ttl=timedelta(minutes=30),\n",
    "    tools=\"code_execution\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'google.generativeai' has no attribute 'generation_types'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 40\u001b[0m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel\u001b[38;5;241m.\u001b[39mfrom_cached_content(cached_content\u001b[38;5;241m=\u001b[39mcache)\n\u001b[1;32m      7\u001b[0m chat \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mstart_chat()\n\u001b[1;32m      9\u001b[0m result \u001b[38;5;241m=\u001b[39m chat\u001b[38;5;241m.\u001b[39msend_message(\n\u001b[1;32m     10\u001b[0m     textwrap\u001b[38;5;241m.\u001b[39mdedent(\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m        You are provided with a CSV file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_file\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This file contains a header row and uses commas as delimiters. The data will be used for a binary classification task in Pycaret, an AutoML library in Python. To prepare the data using the `setup()` function, analyse the data using code execution tool and then based on the analysis, generate the following parameters in JSON format:\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m        \u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m        Remember that performing a binary classification to predict depression target variable based on various features. The parameters to generate are as follows:\u001b[39m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;124m        * **`numeric_features`:**  A list of column names with numeric features.\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124m        * **`categorical_features`:** A list of column names with categorical features.\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124m        * **`ignore_features`:** A list of column names to be ignored during model training. These features might be irrelevant to the target variable in this case \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepression\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m column, redundant with other features, or could introduce data leakage.\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124m        * **`fix_imbalance`:**  A boolean value indicating whether to handle class imbalance. If true, use oversampling to address the imbalance.\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124m        * **`remove_outliers`:** A boolean value indicating whether to remove outliers.\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124m        * **`imputation_type`:** The type of imputation to use for missing values. Choose between \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimple\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (mean/median imputation) or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterative\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (k-Nearest Neighbors imputation).\u001b[39m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;124m        All parameters are required.\u001b[39m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;124m        **Example JSON Response:**\u001b[39m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;124m        ```json\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric_features\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincome\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcredit_score\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m],\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_features\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meducation\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m],\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore_features\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m],\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfix_imbalance\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: true,\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mremove_outliers\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: true,\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimputation_type\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miterative\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124m        ```\u001b[39m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     39\u001b[0m     ),\n\u001b[0;32m---> 40\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39m\u001b[43mTypedDictGenerationConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDataPreparationSchema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_mime_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     44\u001b[0m     request_options\u001b[38;5;241m=\u001b[39mretry_policy,\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m<string>:16\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, candidate_count, stop_sequences, max_output_tokens, temperature, top_p, top_k, seed, response_mime_type, response_schema, presence_penalty, frequency_penalty, response_logprobs, logprobs)\u001b[0m\n",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m, in \u001b[0;36mTypedDictGenerationConfig.__post_init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__post_init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     16\u001b[0m     config \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerationConfig(response_schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_schema)\n\u001b[0;32m---> 17\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43mgenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneration_types\u001b[49m\u001b[38;5;241m.\u001b[39mto_generation_config_dict(config)\n\u001b[1;32m     18\u001b[0m     schema \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_schema\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     19\u001b[0m     schema\u001b[38;5;241m.\u001b[39mrequired \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_schema\u001b[38;5;241m.\u001b[39m__required_keys__)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'google.generativeai' has no attribute 'generation_types'"
     ]
    }
   ],
   "source": [
    "from google.api_core import retry\n",
    "\n",
    "\n",
    "retry_policy = {\"retry\": retry.Retry(predicate=retry.if_transient_error)}\n",
    "\n",
    "model = genai.GenerativeModel.from_cached_content(cached_content=cache)\n",
    "\n",
    "chat = model.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat.send_message(\n",
    "    textwrap.dedent(\n",
    "        f\"\"\"\n",
    "        You are provided with a CSV file {csv_file.name}. This file contains a header row and uses commas as delimiters. The data will be used for a binary classification task in Pycaret, an AutoML library in Python. To prepare the data using the `setup()` function, analyse the data using code execution tool and then based on the analysis, generate the following parameters in JSON format:\n",
    "        \n",
    "        Remember that performing a binary classification to predict depression target variable based on various features. The parameters to generate are as follows:\n",
    "\n",
    "        * **`numeric_features`:**  A list of column names with numeric features.\n",
    "        * **`categorical_features`:** A list of column names with categorical features.\n",
    "        * **`ignore_features`:** A list of column names to be ignored during model training. These features might be irrelevant to the target variable in this case 'depression' column, redundant with other features, or could introduce data leakage.\n",
    "        * **`fix_imbalance`:**  A boolean value indicating whether to handle class imbalance. If true, use oversampling to address the imbalance.\n",
    "        * **`remove_outliers`:** A boolean value indicating whether to remove outliers.\n",
    "        * **`imputation_type`:** The type of imputation to use for missing values. Choose between 'simple' (mean/median imputation) or 'iterative' (k-Nearest Neighbors imputation).\n",
    "\n",
    "        All parameters are required.\n",
    "\n",
    "        **Example JSON Response:**\n",
    "\n",
    "        ```json\n",
    "        {{\n",
    "        \"numeric_features\": [\"age\", \"income\", \"credit_score\"],\n",
    "        \"categorical_features\": [\"gender\", \"education\", \"city\"],\n",
    "        \"ignore_features\": [\"customer_id\", \"date\"],\n",
    "        \"fix_imbalance\": true,\n",
    "        \"remove_outliers\": true,\n",
    "        \"imputation_type\": \"iterative\" \n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        \"\"\"\n",
    "    ),\n",
    "    generation_config=genai.GenerationConfig(\n",
    "        response_schema=get_dict_schema(DataPreparationSchema),\n",
    "        response_mime_type=\"application/json\",\n",
    "    ),\n",
    "    request_options=retry_policy,\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat.send_message(\n",
    "    textwrap.dedent(\n",
    "        f\"\"\"\n",
    "        You are provided with a CSV file {csv_file.name}. This file contains a header row and uses commas as delimiters. The data will be used for a binary classification task in Pycaret, an AutoML library in Python. To prepare the data using the `setup()` function, analyse the data using code execution tool and then based on the analysis, generate the following parameters in JSON format:\n",
    "        \n",
    "        Remember that performing a binary classification to predict depression target variable based on various features. The parameters to generate are as follows:\n",
    "\n",
    "        * normalize: A boolean value indicating whether to normalize the data. If true, the data will be scaled to have a mean of 0 and a standard deviation of 1.\n",
    "        * transformation: A boolean value indicating whether to apply a transformation to the data. If true, the data will be transformed using a power transformation.\n",
    "\n",
    "        All parameters are required.\n",
    "\n",
    "        **Example JSON Response:**\n",
    "\n",
    "        ```json\n",
    "        {{\n",
    "       \"normalize\": true,\n",
    "        \"transformation\": true\n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        \"\"\"\n",
    "    ),\n",
    "    generation_config=genai.GenerationConfig(\n",
    "        response_schema=get_dict_schema(ScaleAndTransformSchema),\n",
    "        response_mime_type=\"application/json\",\n",
    "    ),\n",
    "    request_options=retry_policy,\n",
    ")\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat.send_message(\n",
    "    textwrap.dedent(\n",
    "        f\"\"\"\n",
    "        You are provided with a CSV file {csv_file.name}. This file contains a header row and uses commas as delimiters. The data will be used for a binary classification task in Pycaret, an AutoML library in Python. To prepare the data using the `setup()` function, analyse the data using code execution tool and then based on the analysis, generate the following parameters in JSON format:\n",
    "        \n",
    "        Remember that performing a binary classification to predict depression target variable based on various features. The parameters to generate are as follows:\n",
    "\n",
    "        * polynomial_features: A boolean value indicating whether to generate polynomial features. If true, polynomial features will be created based on the specified degree.\n",
    "        * polynomial_degree: An integer specifying the degree of polynomial features to generate. This parameter is required if polynomial_features is set to true.\n",
    "        * group_features: A list of column names to group together for feature engineering. This parameter is optional. If provided, the features in the list will be grouped together for feature engineering.\n",
    "        * bin_numeric_features: A list of column names with numeric features to bin into discrete intervals. This parameter is optional. If provided, the numeric features will be binned into discrete intervals.\n",
    "        * rare_to_value: A float value specifying the threshold for rare categories. Categories with a frequency less than this threshold will be replaced with a specified value. This parameter is optional and only applicable to categorical features.\n",
    "        \n",
    "\n",
    "        All parameters are required.\n",
    "\n",
    "        **Example JSON Response:**\n",
    "\n",
    "        ```json\n",
    "        {{\n",
    "            polynomial_features: true,\n",
    "            polynomial_degree: 2,\n",
    "            group_features: [\"age\", \"income\"],\n",
    "            bin_numeric_features: [\"credit_score\"],\n",
    "            rare_to_value: 0.01\n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        \"\"\"\n",
    "    ),\n",
    "    generation_config=genai.GenerationConfig(\n",
    "        response_schema=get_dict_schema(FeatureEngineeringSchema),\n",
    "        response_mime_type=\"application/json\",\n",
    "    ),\n",
    "    request_options=retry_policy,\n",
    ")\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat.send_message(\n",
    "    textwrap.dedent(\n",
    "        f\"\"\"\n",
    "        You are provided with a CSV file {csv_file.name}. This file contains a header row and uses commas as delimiters. The data will be used for a binary classification task in Pycaret, an AutoML library in Python. To prepare the data using the `setup()` function, analyse the data using code execution tool and then based on the analysis, generate the following parameters in JSON format:\n",
    "        \n",
    "        Remember that performing a binary classification to predict depression target variable based on various features. The parameters to generate are as follows:\n",
    "\n",
    "        * feature_selection: A boolean value indicating whether to perform feature selection. If true, feature selection will be performed based on the specified criteria.\n",
    "        * n_features_to_select: A float value specifying the number of features to select. This parameter is optional and only applicable if feature_selection is set to true.\n",
    "        * remove_multicollinearity: A boolean value indicating whether to remove multicollinear features. If true, multicollinear features will be removed.\n",
    "        * low_variance_threshold: A float value specifying the threshold for low variance features. Features with a variance less than this threshold will be removed. This parameter is optional\n",
    "        \n",
    "\n",
    "        All parameters are required.\n",
    "\n",
    "        **Example JSON Response:**\n",
    "\n",
    "        ```json\n",
    "        {{\n",
    "            feature_selection: true,\n",
    "            n_features_to_select: 0.5,\n",
    "            remove_multicollinearity: true,\n",
    "            low_variance_threshold: 0.01\n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        \"\"\"\n",
    "    ),\n",
    "    generation_config=genai.GenerationConfig(\n",
    "        response_schema=get_dict_schema(FeatureSelectionSchema),\n",
    "        response_mime_type=\"application/json\",\n",
    "    ),\n",
    "    request_options=retry_policy,\n",
    ")\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
