{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "I was looking into the latest Kaggle competitions and two of them caught my eye. The first one is the Playground series on Depression detection and the other one is the Gemini Long Context usecases. Binary classification is a common problem in machine learning and I thought how about I try to solve both of them in one go. So, here is how I went about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More context\n",
    "\n",
    "Context window is the number of tokens that the model can remember, and tokens are the words or characters that make up the input text. Gemini is one of the unique models that can remember a large number of tokens. Gemini flash comes with 1 million token context window and Gemini 1.5 comes with 2 million token context window.\n",
    "\n",
    "However context window usage by sending large documents (or datasets) in our case, can be expensive and slow. Fortunately, Gemini also provides context caching. Context caching is a way to store the context in the model and reuse it for future requests. This can be done by sending the context once and then sending only the new tokens in the subsequent requests! Cheap and fast!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How did I go about solving the problem?\n",
    "\n",
    "Usually, when we want to quickly dip our toes and get a sense of a common ML problem, like binary classification, we use AutoML libraries. One of the popular AutoML library is PyCaret. PyCaret is an open-source, low-code machine learning library in Python that allows you to go from preparing your data to deploying your model within minutes in your choice of notebook environment. However, to get a bit better results, we need to tweak the arguments of the PyCaret functions. For example, there are multiple choices that we have  to make when we do data preparation and feature engineering steps. Similarly after training a bunch of models, we'll have to decide on whether to ensemble them or not and which type of ensemble to use.\n",
    "\n",
    "Either we can do all of this manually or we can give Gemini all the information as a context and let it do the heavy lifting for us. This is where the context caching comes in handy. So, I decided to extract relevant documentation from PyCaret docs and sliced the dataset into a smaller CSV file and uploaded it to Gemini. As these context can be cached, I can reuse them for future requests and enable Gemini to train the binary classification model for me.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the expected outcome?\n",
    "\n",
    "I am just curious what will be the leaderboard score on both the competitions :D\n",
    "\n",
    "My best guess is that the model will perform better than a base PyCaret AutoML model with default settings. However, I'm sure it won't beat the top models on the leaderboard (probably will come in the top 25 percentile). But hey, it's worth a shot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "SEED = 42\n",
    "MODEL = \"models/gemini-1.5-flash-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import google.generativeai as genai\n",
    "from fastkaggle.core import iskaggle\n",
    "\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if iskaggle:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "else:\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "dataset_path = Path(\"/kaggle/input/playground-series-s4e11\")\n",
    "output_path = Path(\"/kaggle/working\")\n",
    "\n",
    "if not iskaggle:\n",
    "    import kagglehub\n",
    "\n",
    "    dataset_path = kagglehub.competition_download(\"playground-series-s4e11\")\n",
    "    dataset_path = Path(dataset_path)\n",
    "    output_path = Path(dataset_path)\n",
    "\n",
    "train_csv_path = dataset_path / \"train.csv\"\n",
    "test_csv_path = dataset_path / \"test.csv\"\n",
    "submission_csv_path = dataset_path / \"sample_submission.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(train_csv_path, index_col=0)\n",
    "test_df = pd.read_csv(test_csv_path, index_col=0)\n",
    "submission_df = pd.read_csv(submission_csv_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def convert_to_snake_case(s):\n",
    "    \"\"\"\n",
    "    Convert a string to snake_case.\n",
    "    \"\"\"\n",
    "\n",
    "    s = re.sub(r\"[^\\w\\s]\", \" \", s)\n",
    "    return s.lower().strip().replace(\" \", \"_\")\n",
    "\n",
    "\n",
    "train_df.columns = [convert_to_snake_case(col) for col in train_df.columns]\n",
    "test_df.columns = [convert_to_snake_case(col) for col in test_df.columns]\n",
    "submission_df.columns = [convert_to_snake_case(col) for col in submission_df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyCaret AutoML with default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_eb239_row11_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_eb239\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_eb239_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_eb239_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_eb239_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_eb239_row0_col1\" class=\"data row0 col1\" >4441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_eb239_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_eb239_row1_col1\" class=\"data row1 col1\" >depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_eb239_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_eb239_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_eb239_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_eb239_row3_col1\" class=\"data row3 col1\" >(140700, 19)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_eb239_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_eb239_row4_col1\" class=\"data row4 col1\" >(140700, 35)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_eb239_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_eb239_row5_col1\" class=\"data row5 col1\" >(98490, 35)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_eb239_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_eb239_row6_col1\" class=\"data row6 col1\" >(42210, 35)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_eb239_row7_col0\" class=\"data row7 col0\" >Ordinal features</td>\n",
       "      <td id=\"T_eb239_row7_col1\" class=\"data row7 col1\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_eb239_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_eb239_row8_col1\" class=\"data row8 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_eb239_row9_col0\" class=\"data row9 col0\" >Categorical features</td>\n",
       "      <td id=\"T_eb239_row9_col1\" class=\"data row9 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_eb239_row10_col0\" class=\"data row10 col0\" >Rows with missing values</td>\n",
       "      <td id=\"T_eb239_row10_col1\" class=\"data row10 col1\" >100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_eb239_row11_col0\" class=\"data row11 col0\" >Preprocess</td>\n",
       "      <td id=\"T_eb239_row11_col1\" class=\"data row11 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_eb239_row12_col0\" class=\"data row12 col0\" >Imputation type</td>\n",
       "      <td id=\"T_eb239_row12_col1\" class=\"data row12 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_eb239_row13_col0\" class=\"data row13 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_eb239_row13_col1\" class=\"data row13 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_eb239_row14_col0\" class=\"data row14 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_eb239_row14_col1\" class=\"data row14 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_eb239_row15_col0\" class=\"data row15 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_eb239_row15_col1\" class=\"data row15 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_eb239_row16_col0\" class=\"data row16 col0\" >Encoding method</td>\n",
       "      <td id=\"T_eb239_row16_col1\" class=\"data row16 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_eb239_row17_col0\" class=\"data row17 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_eb239_row17_col1\" class=\"data row17 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_eb239_row18_col0\" class=\"data row18 col0\" >Fold Number</td>\n",
       "      <td id=\"T_eb239_row18_col1\" class=\"data row18 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_eb239_row19_col0\" class=\"data row19 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_eb239_row19_col1\" class=\"data row19 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_eb239_row20_col0\" class=\"data row20 col0\" >Use GPU</td>\n",
       "      <td id=\"T_eb239_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_eb239_row21_col0\" class=\"data row21 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_eb239_row21_col1\" class=\"data row21 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_eb239_row22_col0\" class=\"data row22 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_eb239_row22_col1\" class=\"data row22 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb239_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_eb239_row23_col0\" class=\"data row23 col0\" >USI</td>\n",
       "      <td id=\"T_eb239_row23_col1\" class=\"data row23 col1\" >6b09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x311e54a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x3d2997390>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pycaret.classification import ClassificationExperiment\n",
    "\n",
    "experiment = ClassificationExperiment()\n",
    "\n",
    "# Just filling the required fields here. These are the default settings. I'm not cheating!\n",
    "experiment.setup(data=train_df, target=\"depression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_628b2 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_628b2_row0_col0, #T_628b2_row0_col3, #T_628b2_row0_col4, #T_628b2_row1_col0, #T_628b2_row1_col1, #T_628b2_row1_col2, #T_628b2_row1_col3, #T_628b2_row1_col4, #T_628b2_row1_col5, #T_628b2_row1_col6, #T_628b2_row1_col7, #T_628b2_row2_col0, #T_628b2_row2_col1, #T_628b2_row2_col2, #T_628b2_row2_col3, #T_628b2_row2_col4, #T_628b2_row2_col5, #T_628b2_row2_col6, #T_628b2_row2_col7, #T_628b2_row3_col0, #T_628b2_row3_col1, #T_628b2_row3_col2, #T_628b2_row3_col3, #T_628b2_row3_col4, #T_628b2_row3_col5, #T_628b2_row3_col6, #T_628b2_row3_col7, #T_628b2_row4_col0, #T_628b2_row4_col1, #T_628b2_row4_col2, #T_628b2_row4_col3, #T_628b2_row4_col4, #T_628b2_row4_col5, #T_628b2_row4_col6, #T_628b2_row4_col7, #T_628b2_row5_col0, #T_628b2_row5_col1, #T_628b2_row5_col2, #T_628b2_row5_col3, #T_628b2_row5_col5, #T_628b2_row5_col6, #T_628b2_row5_col7, #T_628b2_row6_col0, #T_628b2_row6_col1, #T_628b2_row6_col2, #T_628b2_row6_col3, #T_628b2_row6_col4, #T_628b2_row6_col5, #T_628b2_row6_col6, #T_628b2_row6_col7, #T_628b2_row7_col0, #T_628b2_row7_col1, #T_628b2_row7_col2, #T_628b2_row7_col3, #T_628b2_row7_col4, #T_628b2_row7_col5, #T_628b2_row7_col6, #T_628b2_row7_col7, #T_628b2_row8_col0, #T_628b2_row8_col1, #T_628b2_row8_col2, #T_628b2_row8_col3, #T_628b2_row8_col4, #T_628b2_row8_col5, #T_628b2_row8_col6, #T_628b2_row8_col7, #T_628b2_row9_col0, #T_628b2_row9_col1, #T_628b2_row9_col2, #T_628b2_row9_col3, #T_628b2_row9_col4, #T_628b2_row9_col5, #T_628b2_row9_col6, #T_628b2_row9_col7, #T_628b2_row10_col0, #T_628b2_row10_col1, #T_628b2_row10_col2, #T_628b2_row10_col3, #T_628b2_row10_col4, #T_628b2_row10_col5, #T_628b2_row10_col6, #T_628b2_row10_col7, #T_628b2_row11_col0, #T_628b2_row11_col1, #T_628b2_row11_col2, #T_628b2_row11_col3, #T_628b2_row11_col4, #T_628b2_row11_col5, #T_628b2_row11_col6, #T_628b2_row11_col7, #T_628b2_row12_col0, #T_628b2_row12_col1, #T_628b2_row12_col2, #T_628b2_row12_col3, #T_628b2_row12_col4, #T_628b2_row12_col5, #T_628b2_row12_col6, #T_628b2_row12_col7, #T_628b2_row13_col0, #T_628b2_row13_col1, #T_628b2_row13_col2, #T_628b2_row13_col3, #T_628b2_row13_col4, #T_628b2_row13_col5, #T_628b2_row13_col6, #T_628b2_row13_col7, #T_628b2_row14_col0, #T_628b2_row14_col1, #T_628b2_row14_col2, #T_628b2_row14_col3, #T_628b2_row14_col4, #T_628b2_row14_col5, #T_628b2_row14_col6, #T_628b2_row14_col7, #T_628b2_row15_col0, #T_628b2_row15_col1, #T_628b2_row15_col2, #T_628b2_row15_col4, #T_628b2_row15_col5, #T_628b2_row15_col6, #T_628b2_row15_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_628b2_row0_col1, #T_628b2_row0_col2, #T_628b2_row0_col5, #T_628b2_row0_col6, #T_628b2_row0_col7, #T_628b2_row5_col4, #T_628b2_row15_col3 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_628b2_row0_col8, #T_628b2_row1_col8, #T_628b2_row2_col8, #T_628b2_row3_col8, #T_628b2_row5_col8, #T_628b2_row6_col8, #T_628b2_row7_col8, #T_628b2_row8_col8, #T_628b2_row9_col8, #T_628b2_row10_col8, #T_628b2_row11_col8, #T_628b2_row12_col8, #T_628b2_row13_col8, #T_628b2_row14_col8, #T_628b2_row15_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_628b2_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_628b2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_628b2_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_628b2_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_628b2_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_628b2_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_628b2_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_628b2_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_628b2_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_628b2_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_628b2_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_628b2_level0_row0\" class=\"row_heading level0 row0\" >lr</th>\n",
       "      <td id=\"T_628b2_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_628b2_row0_col1\" class=\"data row0 col1\" >0.9372</td>\n",
       "      <td id=\"T_628b2_row0_col2\" class=\"data row0 col2\" >0.9734</td>\n",
       "      <td id=\"T_628b2_row0_col3\" class=\"data row0 col3\" >0.8034</td>\n",
       "      <td id=\"T_628b2_row0_col4\" class=\"data row0 col4\" >0.8435</td>\n",
       "      <td id=\"T_628b2_row0_col5\" class=\"data row0 col5\" >0.8229</td>\n",
       "      <td id=\"T_628b2_row0_col6\" class=\"data row0 col6\" >0.7847</td>\n",
       "      <td id=\"T_628b2_row0_col7\" class=\"data row0 col7\" >0.7851</td>\n",
       "      <td id=\"T_628b2_row0_col8\" class=\"data row0 col8\" >1.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_628b2_level0_row1\" class=\"row_heading level0 row1\" >svm</th>\n",
       "      <td id=\"T_628b2_row1_col0\" class=\"data row1 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_628b2_row1_col1\" class=\"data row1 col1\" >0.9319</td>\n",
       "      <td id=\"T_628b2_row1_col2\" class=\"data row1 col2\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row1_col3\" class=\"data row1 col3\" >0.7735</td>\n",
       "      <td id=\"T_628b2_row1_col4\" class=\"data row1 col4\" >0.8463</td>\n",
       "      <td id=\"T_628b2_row1_col5\" class=\"data row1 col5\" >0.8042</td>\n",
       "      <td id=\"T_628b2_row1_col6\" class=\"data row1 col6\" >0.7633</td>\n",
       "      <td id=\"T_628b2_row1_col7\" class=\"data row1 col7\" >0.7672</td>\n",
       "      <td id=\"T_628b2_row1_col8\" class=\"data row1 col8\" >0.4040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_628b2_level0_row2\" class=\"row_heading level0 row2\" >lda</th>\n",
       "      <td id=\"T_628b2_row2_col0\" class=\"data row2 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_628b2_row2_col1\" class=\"data row2 col1\" >0.9259</td>\n",
       "      <td id=\"T_628b2_row2_col2\" class=\"data row2 col2\" >0.9670</td>\n",
       "      <td id=\"T_628b2_row2_col3\" class=\"data row2 col3\" >0.7600</td>\n",
       "      <td id=\"T_628b2_row2_col4\" class=\"data row2 col4\" >0.8194</td>\n",
       "      <td id=\"T_628b2_row2_col5\" class=\"data row2 col5\" >0.7886</td>\n",
       "      <td id=\"T_628b2_row2_col6\" class=\"data row2 col6\" >0.7438</td>\n",
       "      <td id=\"T_628b2_row2_col7\" class=\"data row2 col7\" >0.7445</td>\n",
       "      <td id=\"T_628b2_row2_col8\" class=\"data row2 col8\" >0.5820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_628b2_level0_row3\" class=\"row_heading level0 row3\" >knn</th>\n",
       "      <td id=\"T_628b2_row3_col0\" class=\"data row3 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_628b2_row3_col1\" class=\"data row3 col1\" >0.9229</td>\n",
       "      <td id=\"T_628b2_row3_col2\" class=\"data row3 col2\" >0.9383</td>\n",
       "      <td id=\"T_628b2_row3_col3\" class=\"data row3 col3\" >0.7812</td>\n",
       "      <td id=\"T_628b2_row3_col4\" class=\"data row3 col4\" >0.7917</td>\n",
       "      <td id=\"T_628b2_row3_col5\" class=\"data row3 col5\" >0.7863</td>\n",
       "      <td id=\"T_628b2_row3_col6\" class=\"data row3 col6\" >0.7393</td>\n",
       "      <td id=\"T_628b2_row3_col7\" class=\"data row3 col7\" >0.7393</td>\n",
       "      <td id=\"T_628b2_row3_col8\" class=\"data row3 col8\" >1.2660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_628b2_level0_row4\" class=\"row_heading level0 row4\" >ridge</th>\n",
       "      <td id=\"T_628b2_row4_col0\" class=\"data row4 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_628b2_row4_col1\" class=\"data row4 col1\" >0.9221</td>\n",
       "      <td id=\"T_628b2_row4_col2\" class=\"data row4 col2\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row4_col3\" class=\"data row4 col3\" >0.6982</td>\n",
       "      <td id=\"T_628b2_row4_col4\" class=\"data row4 col4\" >0.8465</td>\n",
       "      <td id=\"T_628b2_row4_col5\" class=\"data row4 col5\" >0.7651</td>\n",
       "      <td id=\"T_628b2_row4_col6\" class=\"data row4 col6\" >0.7190</td>\n",
       "      <td id=\"T_628b2_row4_col7\" class=\"data row4 col7\" >0.7238</td>\n",
       "      <td id=\"T_628b2_row4_col8\" class=\"data row4 col8\" >0.1570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_628b2_level0_row5\" class=\"row_heading level0 row5\" >et</th>\n",
       "      <td id=\"T_628b2_row5_col0\" class=\"data row5 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_628b2_row5_col1\" class=\"data row5 col1\" >0.8753</td>\n",
       "      <td id=\"T_628b2_row5_col2\" class=\"data row5 col2\" >0.9613</td>\n",
       "      <td id=\"T_628b2_row5_col3\" class=\"data row5 col3\" >0.3436</td>\n",
       "      <td id=\"T_628b2_row5_col4\" class=\"data row5 col4\" >0.9208</td>\n",
       "      <td id=\"T_628b2_row5_col5\" class=\"data row5 col5\" >0.4995</td>\n",
       "      <td id=\"T_628b2_row5_col6\" class=\"data row5 col6\" >0.4450</td>\n",
       "      <td id=\"T_628b2_row5_col7\" class=\"data row5 col7\" >0.5164</td>\n",
       "      <td id=\"T_628b2_row5_col8\" class=\"data row5 col8\" >0.9270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_628b2_level0_row6\" class=\"row_heading level0 row6\" >nb</th>\n",
       "      <td id=\"T_628b2_row6_col0\" class=\"data row6 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_628b2_row6_col1\" class=\"data row6 col1\" >0.8309</td>\n",
       "      <td id=\"T_628b2_row6_col2\" class=\"data row6 col2\" >0.9238</td>\n",
       "      <td id=\"T_628b2_row6_col3\" class=\"data row6 col3\" >0.9206</td>\n",
       "      <td id=\"T_628b2_row6_col4\" class=\"data row6 col4\" >0.5277</td>\n",
       "      <td id=\"T_628b2_row6_col5\" class=\"data row6 col5\" >0.6667</td>\n",
       "      <td id=\"T_628b2_row6_col6\" class=\"data row6 col6\" >0.5659</td>\n",
       "      <td id=\"T_628b2_row6_col7\" class=\"data row6 col7\" >0.6086</td>\n",
       "      <td id=\"T_628b2_row6_col8\" class=\"data row6 col8\" >0.1770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_628b2_level0_row7\" class=\"row_heading level0 row7\" >rf</th>\n",
       "      <td id=\"T_628b2_row7_col0\" class=\"data row7 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_628b2_row7_col1\" class=\"data row7 col1\" >0.8252</td>\n",
       "      <td id=\"T_628b2_row7_col2\" class=\"data row7 col2\" >0.8636</td>\n",
       "      <td id=\"T_628b2_row7_col3\" class=\"data row7 col3\" >0.0461</td>\n",
       "      <td id=\"T_628b2_row7_col4\" class=\"data row7 col4\" >0.8477</td>\n",
       "      <td id=\"T_628b2_row7_col5\" class=\"data row7 col5\" >0.0874</td>\n",
       "      <td id=\"T_628b2_row7_col6\" class=\"data row7 col6\" >0.0700</td>\n",
       "      <td id=\"T_628b2_row7_col7\" class=\"data row7 col7\" >0.1724</td>\n",
       "      <td id=\"T_628b2_row7_col8\" class=\"data row7 col8\" >0.9460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_628b2_level0_row8\" class=\"row_heading level0 row8\" >ada</th>\n",
       "      <td id=\"T_628b2_row8_col0\" class=\"data row8 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_628b2_row8_col1\" class=\"data row8 col1\" >0.8183</td>\n",
       "      <td id=\"T_628b2_row8_col2\" class=\"data row8 col2\" >0.6146</td>\n",
       "      <td id=\"T_628b2_row8_col3\" class=\"data row8 col3\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row8_col4\" class=\"data row8 col4\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row8_col5\" class=\"data row8 col5\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row8_col6\" class=\"data row8 col6\" >-0.0001</td>\n",
       "      <td id=\"T_628b2_row8_col7\" class=\"data row8 col7\" >-0.0014</td>\n",
       "      <td id=\"T_628b2_row8_col8\" class=\"data row8 col8\" >0.6450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_628b2_level0_row9\" class=\"row_heading level0 row9\" >gbc</th>\n",
       "      <td id=\"T_628b2_row9_col0\" class=\"data row9 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_628b2_row9_col1\" class=\"data row9 col1\" >0.8183</td>\n",
       "      <td id=\"T_628b2_row9_col2\" class=\"data row9 col2\" >0.3948</td>\n",
       "      <td id=\"T_628b2_row9_col3\" class=\"data row9 col3\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row9_col4\" class=\"data row9 col4\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row9_col5\" class=\"data row9 col5\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row9_col6\" class=\"data row9 col6\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row9_col7\" class=\"data row9 col7\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row9_col8\" class=\"data row9 col8\" >2.2630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_628b2_level0_row10\" class=\"row_heading level0 row10\" >lightgbm</th>\n",
       "      <td id=\"T_628b2_row10_col0\" class=\"data row10 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_628b2_row10_col1\" class=\"data row10 col1\" >0.8183</td>\n",
       "      <td id=\"T_628b2_row10_col2\" class=\"data row10 col2\" >0.1992</td>\n",
       "      <td id=\"T_628b2_row10_col3\" class=\"data row10 col3\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row10_col4\" class=\"data row10 col4\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row10_col5\" class=\"data row10 col5\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row10_col6\" class=\"data row10 col6\" >-0.0000</td>\n",
       "      <td id=\"T_628b2_row10_col7\" class=\"data row10 col7\" >-0.0005</td>\n",
       "      <td id=\"T_628b2_row10_col8\" class=\"data row10 col8\" >0.6270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_628b2_level0_row11\" class=\"row_heading level0 row11\" >catboost</th>\n",
       "      <td id=\"T_628b2_row11_col0\" class=\"data row11 col0\" >CatBoost Classifier</td>\n",
       "      <td id=\"T_628b2_row11_col1\" class=\"data row11 col1\" >0.8183</td>\n",
       "      <td id=\"T_628b2_row11_col2\" class=\"data row11 col2\" >0.8112</td>\n",
       "      <td id=\"T_628b2_row11_col3\" class=\"data row11 col3\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row11_col4\" class=\"data row11 col4\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row11_col5\" class=\"data row11 col5\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row11_col6\" class=\"data row11 col6\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row11_col7\" class=\"data row11 col7\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row11_col8\" class=\"data row11 col8\" >3.2890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_628b2_level0_row12\" class=\"row_heading level0 row12\" >dummy</th>\n",
       "      <td id=\"T_628b2_row12_col0\" class=\"data row12 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_628b2_row12_col1\" class=\"data row12 col1\" >0.8183</td>\n",
       "      <td id=\"T_628b2_row12_col2\" class=\"data row12 col2\" >0.5000</td>\n",
       "      <td id=\"T_628b2_row12_col3\" class=\"data row12 col3\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row12_col4\" class=\"data row12 col4\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row12_col5\" class=\"data row12 col5\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row12_col6\" class=\"data row12 col6\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row12_col7\" class=\"data row12 col7\" >0.0000</td>\n",
       "      <td id=\"T_628b2_row12_col8\" class=\"data row12 col8\" >0.1810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_628b2_level0_row13\" class=\"row_heading level0 row13\" >dt</th>\n",
       "      <td id=\"T_628b2_row13_col0\" class=\"data row13 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_628b2_row13_col1\" class=\"data row13 col1\" >0.8072</td>\n",
       "      <td id=\"T_628b2_row13_col2\" class=\"data row13 col2\" >0.4958</td>\n",
       "      <td id=\"T_628b2_row13_col3\" class=\"data row13 col3\" >0.0065</td>\n",
       "      <td id=\"T_628b2_row13_col4\" class=\"data row13 col4\" >0.0914</td>\n",
       "      <td id=\"T_628b2_row13_col5\" class=\"data row13 col5\" >0.0122</td>\n",
       "      <td id=\"T_628b2_row13_col6\" class=\"data row13 col6\" >-0.0131</td>\n",
       "      <td id=\"T_628b2_row13_col7\" class=\"data row13 col7\" >-0.0276</td>\n",
       "      <td id=\"T_628b2_row13_col8\" class=\"data row13 col8\" >0.2310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_628b2_level0_row14\" class=\"row_heading level0 row14\" >qda</th>\n",
       "      <td id=\"T_628b2_row14_col0\" class=\"data row14 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_628b2_row14_col1\" class=\"data row14 col1\" >0.1823</td>\n",
       "      <td id=\"T_628b2_row14_col2\" class=\"data row14 col2\" >0.5251</td>\n",
       "      <td id=\"T_628b2_row14_col3\" class=\"data row14 col3\" >0.9998</td>\n",
       "      <td id=\"T_628b2_row14_col4\" class=\"data row14 col4\" >0.1818</td>\n",
       "      <td id=\"T_628b2_row14_col5\" class=\"data row14 col5\" >0.3077</td>\n",
       "      <td id=\"T_628b2_row14_col6\" class=\"data row14 col6\" >0.0002</td>\n",
       "      <td id=\"T_628b2_row14_col7\" class=\"data row14 col7\" >-0.0015</td>\n",
       "      <td id=\"T_628b2_row14_col8\" class=\"data row14 col8\" >0.1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_628b2_level0_row15\" class=\"row_heading level0 row15\" >xgboost</th>\n",
       "      <td id=\"T_628b2_row15_col0\" class=\"data row15 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_628b2_row15_col1\" class=\"data row15 col1\" >0.1820</td>\n",
       "      <td id=\"T_628b2_row15_col2\" class=\"data row15 col2\" >0.9162</td>\n",
       "      <td id=\"T_628b2_row15_col3\" class=\"data row15 col3\" >0.9999</td>\n",
       "      <td id=\"T_628b2_row15_col4\" class=\"data row15 col4\" >0.1818</td>\n",
       "      <td id=\"T_628b2_row15_col5\" class=\"data row15 col5\" >0.3076</td>\n",
       "      <td id=\"T_628b2_row15_col6\" class=\"data row15 col6\" >0.0001</td>\n",
       "      <td id=\"T_628b2_row15_col7\" class=\"data row15 col7\" >0.0067</td>\n",
       "      <td id=\"T_628b2_row15_col8\" class=\"data row15 col8\" >0.3110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x31a66ba90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987d00ba6d7e42f69b75c0975ce61fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top5 = experiment.compare_models(n_select=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_71904_row10_col0, #T_71904_row10_col1, #T_71904_row10_col2, #T_71904_row10_col3, #T_71904_row10_col4, #T_71904_row10_col5, #T_71904_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_71904\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_71904_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_71904_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_71904_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_71904_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_71904_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_71904_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_71904_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_71904_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_71904_row0_col0\" class=\"data row0 col0\" >0.9343</td>\n",
       "      <td id=\"T_71904_row0_col1\" class=\"data row0 col1\" >0.9715</td>\n",
       "      <td id=\"T_71904_row0_col2\" class=\"data row0 col2\" >0.8603</td>\n",
       "      <td id=\"T_71904_row0_col3\" class=\"data row0 col3\" >0.7949</td>\n",
       "      <td id=\"T_71904_row0_col4\" class=\"data row0 col4\" >0.8263</td>\n",
       "      <td id=\"T_71904_row0_col5\" class=\"data row0 col5\" >0.7859</td>\n",
       "      <td id=\"T_71904_row0_col6\" class=\"data row0 col6\" >0.7868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71904_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_71904_row1_col0\" class=\"data row1 col0\" >0.9332</td>\n",
       "      <td id=\"T_71904_row1_col1\" class=\"data row1 col1\" >0.9687</td>\n",
       "      <td id=\"T_71904_row1_col2\" class=\"data row1 col2\" >0.7848</td>\n",
       "      <td id=\"T_71904_row1_col3\" class=\"data row1 col3\" >0.8372</td>\n",
       "      <td id=\"T_71904_row1_col4\" class=\"data row1 col4\" >0.8102</td>\n",
       "      <td id=\"T_71904_row1_col5\" class=\"data row1 col5\" >0.7697</td>\n",
       "      <td id=\"T_71904_row1_col6\" class=\"data row1 col6\" >0.7703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71904_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_71904_row2_col0\" class=\"data row2 col0\" >0.9382</td>\n",
       "      <td id=\"T_71904_row2_col1\" class=\"data row2 col1\" >0.9733</td>\n",
       "      <td id=\"T_71904_row2_col2\" class=\"data row2 col2\" >0.7960</td>\n",
       "      <td id=\"T_71904_row2_col3\" class=\"data row2 col3\" >0.8537</td>\n",
       "      <td id=\"T_71904_row2_col4\" class=\"data row2 col4\" >0.8238</td>\n",
       "      <td id=\"T_71904_row2_col5\" class=\"data row2 col5\" >0.7864</td>\n",
       "      <td id=\"T_71904_row2_col6\" class=\"data row2 col6\" >0.7871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71904_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_71904_row3_col0\" class=\"data row3 col0\" >0.9374</td>\n",
       "      <td id=\"T_71904_row3_col1\" class=\"data row3 col1\" >0.9713</td>\n",
       "      <td id=\"T_71904_row3_col2\" class=\"data row3 col2\" >0.7966</td>\n",
       "      <td id=\"T_71904_row3_col3\" class=\"data row3 col3\" >0.8493</td>\n",
       "      <td id=\"T_71904_row3_col4\" class=\"data row3 col4\" >0.8221</td>\n",
       "      <td id=\"T_71904_row3_col5\" class=\"data row3 col5\" >0.7842</td>\n",
       "      <td id=\"T_71904_row3_col6\" class=\"data row3 col6\" >0.7848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71904_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_71904_row4_col0\" class=\"data row4 col0\" >0.9391</td>\n",
       "      <td id=\"T_71904_row4_col1\" class=\"data row4 col1\" >0.9746</td>\n",
       "      <td id=\"T_71904_row4_col2\" class=\"data row4 col2\" >0.7944</td>\n",
       "      <td id=\"T_71904_row4_col3\" class=\"data row4 col3\" >0.8597</td>\n",
       "      <td id=\"T_71904_row4_col4\" class=\"data row4 col4\" >0.8258</td>\n",
       "      <td id=\"T_71904_row4_col5\" class=\"data row4 col5\" >0.7889</td>\n",
       "      <td id=\"T_71904_row4_col6\" class=\"data row4 col6\" >0.7898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71904_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_71904_row5_col0\" class=\"data row5 col0\" >0.9364</td>\n",
       "      <td id=\"T_71904_row5_col1\" class=\"data row5 col1\" >0.9737</td>\n",
       "      <td id=\"T_71904_row5_col2\" class=\"data row5 col2\" >0.7916</td>\n",
       "      <td id=\"T_71904_row5_col3\" class=\"data row5 col3\" >0.8485</td>\n",
       "      <td id=\"T_71904_row5_col4\" class=\"data row5 col4\" >0.8191</td>\n",
       "      <td id=\"T_71904_row5_col5\" class=\"data row5 col5\" >0.7806</td>\n",
       "      <td id=\"T_71904_row5_col6\" class=\"data row5 col6\" >0.7813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71904_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_71904_row6_col0\" class=\"data row6 col0\" >0.9388</td>\n",
       "      <td id=\"T_71904_row6_col1\" class=\"data row6 col1\" >0.9750</td>\n",
       "      <td id=\"T_71904_row6_col2\" class=\"data row6 col2\" >0.7983</td>\n",
       "      <td id=\"T_71904_row6_col3\" class=\"data row6 col3\" >0.8552</td>\n",
       "      <td id=\"T_71904_row6_col4\" class=\"data row6 col4\" >0.8258</td>\n",
       "      <td id=\"T_71904_row6_col5\" class=\"data row6 col5\" >0.7887</td>\n",
       "      <td id=\"T_71904_row6_col6\" class=\"data row6 col6\" >0.7894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71904_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_71904_row7_col0\" class=\"data row7 col0\" >0.9377</td>\n",
       "      <td id=\"T_71904_row7_col1\" class=\"data row7 col1\" >0.9712</td>\n",
       "      <td id=\"T_71904_row7_col2\" class=\"data row7 col2\" >0.8223</td>\n",
       "      <td id=\"T_71904_row7_col3\" class=\"data row7 col3\" >0.8326</td>\n",
       "      <td id=\"T_71904_row7_col4\" class=\"data row7 col4\" >0.8274</td>\n",
       "      <td id=\"T_71904_row7_col5\" class=\"data row7 col5\" >0.7894</td>\n",
       "      <td id=\"T_71904_row7_col6\" class=\"data row7 col6\" >0.7894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71904_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_71904_row8_col0\" class=\"data row8 col0\" >0.9376</td>\n",
       "      <td id=\"T_71904_row8_col1\" class=\"data row8 col1\" >0.9745</td>\n",
       "      <td id=\"T_71904_row8_col2\" class=\"data row8 col2\" >0.8179</td>\n",
       "      <td id=\"T_71904_row8_col3\" class=\"data row8 col3\" >0.8351</td>\n",
       "      <td id=\"T_71904_row8_col4\" class=\"data row8 col4\" >0.8264</td>\n",
       "      <td id=\"T_71904_row8_col5\" class=\"data row8 col5\" >0.7884</td>\n",
       "      <td id=\"T_71904_row8_col6\" class=\"data row8 col6\" >0.7884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71904_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_71904_row9_col0\" class=\"data row9 col0\" >0.9376</td>\n",
       "      <td id=\"T_71904_row9_col1\" class=\"data row9 col1\" >0.9751</td>\n",
       "      <td id=\"T_71904_row9_col2\" class=\"data row9 col2\" >0.7994</td>\n",
       "      <td id=\"T_71904_row9_col3\" class=\"data row9 col3\" >0.8483</td>\n",
       "      <td id=\"T_71904_row9_col4\" class=\"data row9 col4\" >0.8231</td>\n",
       "      <td id=\"T_71904_row9_col5\" class=\"data row9 col5\" >0.7852</td>\n",
       "      <td id=\"T_71904_row9_col6\" class=\"data row9 col6\" >0.7858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71904_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_71904_row10_col0\" class=\"data row10 col0\" >0.9370</td>\n",
       "      <td id=\"T_71904_row10_col1\" class=\"data row10 col1\" >0.9729</td>\n",
       "      <td id=\"T_71904_row10_col2\" class=\"data row10 col2\" >0.8062</td>\n",
       "      <td id=\"T_71904_row10_col3\" class=\"data row10 col3\" >0.8415</td>\n",
       "      <td id=\"T_71904_row10_col4\" class=\"data row10 col4\" >0.8230</td>\n",
       "      <td id=\"T_71904_row10_col5\" class=\"data row10 col5\" >0.7847</td>\n",
       "      <td id=\"T_71904_row10_col6\" class=\"data row10 col6\" >0.7853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71904_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_71904_row11_col0\" class=\"data row11 col0\" >0.0018</td>\n",
       "      <td id=\"T_71904_row11_col1\" class=\"data row11 col1\" >0.0020</td>\n",
       "      <td id=\"T_71904_row11_col2\" class=\"data row11 col2\" >0.0211</td>\n",
       "      <td id=\"T_71904_row11_col3\" class=\"data row11 col3\" >0.0177</td>\n",
       "      <td id=\"T_71904_row11_col4\" class=\"data row11 col4\" >0.0049</td>\n",
       "      <td id=\"T_71904_row11_col5\" class=\"data row11 col5\" >0.0056</td>\n",
       "      <td id=\"T_71904_row11_col6\" class=\"data row11 col6\" >0.0056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1698b3bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4dbec3021b46ed9549ec50f0842b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model was better than the stacked model, hence it will be returned. NOTE: The display metrics are for the stacked model (not the original one).\n"
     ]
    }
   ],
   "source": [
    "stacked_model = experiment.stack_models(top5, choose_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_23fc5_row10_col0, #T_23fc5_row10_col1, #T_23fc5_row10_col2, #T_23fc5_row10_col3, #T_23fc5_row10_col4, #T_23fc5_row10_col5, #T_23fc5_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_23fc5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_23fc5_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_23fc5_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_23fc5_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_23fc5_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_23fc5_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_23fc5_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_23fc5_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_23fc5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_23fc5_row0_col0\" class=\"data row0 col0\" >0.9312</td>\n",
       "      <td id=\"T_23fc5_row0_col1\" class=\"data row0 col1\" >0.0000</td>\n",
       "      <td id=\"T_23fc5_row0_col2\" class=\"data row0 col2\" >0.7887</td>\n",
       "      <td id=\"T_23fc5_row0_col3\" class=\"data row0 col3\" >0.8247</td>\n",
       "      <td id=\"T_23fc5_row0_col4\" class=\"data row0 col4\" >0.8063</td>\n",
       "      <td id=\"T_23fc5_row0_col5\" class=\"data row0 col5\" >0.7645</td>\n",
       "      <td id=\"T_23fc5_row0_col6\" class=\"data row0 col6\" >0.7647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23fc5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_23fc5_row1_col0\" class=\"data row1 col0\" >0.9314</td>\n",
       "      <td id=\"T_23fc5_row1_col1\" class=\"data row1 col1\" >0.0000</td>\n",
       "      <td id=\"T_23fc5_row1_col2\" class=\"data row1 col2\" >0.7798</td>\n",
       "      <td id=\"T_23fc5_row1_col3\" class=\"data row1 col3\" >0.8318</td>\n",
       "      <td id=\"T_23fc5_row1_col4\" class=\"data row1 col4\" >0.8050</td>\n",
       "      <td id=\"T_23fc5_row1_col5\" class=\"data row1 col5\" >0.7634</td>\n",
       "      <td id=\"T_23fc5_row1_col6\" class=\"data row1 col6\" >0.7640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23fc5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_23fc5_row2_col0\" class=\"data row2 col0\" >0.9367</td>\n",
       "      <td id=\"T_23fc5_row2_col1\" class=\"data row2 col1\" >0.0000</td>\n",
       "      <td id=\"T_23fc5_row2_col2\" class=\"data row2 col2\" >0.7747</td>\n",
       "      <td id=\"T_23fc5_row2_col3\" class=\"data row2 col3\" >0.8630</td>\n",
       "      <td id=\"T_23fc5_row2_col4\" class=\"data row2 col4\" >0.8165</td>\n",
       "      <td id=\"T_23fc5_row2_col5\" class=\"data row2 col5\" >0.7784</td>\n",
       "      <td id=\"T_23fc5_row2_col6\" class=\"data row2 col6\" >0.7801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23fc5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_23fc5_row3_col0\" class=\"data row3 col0\" >0.9294</td>\n",
       "      <td id=\"T_23fc5_row3_col1\" class=\"data row3 col1\" >0.0000</td>\n",
       "      <td id=\"T_23fc5_row3_col2\" class=\"data row3 col2\" >0.7581</td>\n",
       "      <td id=\"T_23fc5_row3_col3\" class=\"data row3 col3\" >0.8382</td>\n",
       "      <td id=\"T_23fc5_row3_col4\" class=\"data row3 col4\" >0.7961</td>\n",
       "      <td id=\"T_23fc5_row3_col5\" class=\"data row3 col5\" >0.7536</td>\n",
       "      <td id=\"T_23fc5_row3_col6\" class=\"data row3 col6\" >0.7550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23fc5_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_23fc5_row4_col0\" class=\"data row4 col0\" >0.9308</td>\n",
       "      <td id=\"T_23fc5_row4_col1\" class=\"data row4 col1\" >0.0000</td>\n",
       "      <td id=\"T_23fc5_row4_col2\" class=\"data row4 col2\" >0.7486</td>\n",
       "      <td id=\"T_23fc5_row4_col3\" class=\"data row4 col3\" >0.8524</td>\n",
       "      <td id=\"T_23fc5_row4_col4\" class=\"data row4 col4\" >0.7971</td>\n",
       "      <td id=\"T_23fc5_row4_col5\" class=\"data row4 col5\" >0.7556</td>\n",
       "      <td id=\"T_23fc5_row4_col6\" class=\"data row4 col6\" >0.7579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23fc5_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_23fc5_row5_col0\" class=\"data row5 col0\" >0.9328</td>\n",
       "      <td id=\"T_23fc5_row5_col1\" class=\"data row5 col1\" >0.0000</td>\n",
       "      <td id=\"T_23fc5_row5_col2\" class=\"data row5 col2\" >0.7654</td>\n",
       "      <td id=\"T_23fc5_row5_col3\" class=\"data row5 col3\" >0.8499</td>\n",
       "      <td id=\"T_23fc5_row5_col4\" class=\"data row5 col4\" >0.8054</td>\n",
       "      <td id=\"T_23fc5_row5_col5\" class=\"data row5 col5\" >0.7649</td>\n",
       "      <td id=\"T_23fc5_row5_col6\" class=\"data row5 col6\" >0.7665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23fc5_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_23fc5_row6_col0\" class=\"data row6 col0\" >0.9339</td>\n",
       "      <td id=\"T_23fc5_row6_col1\" class=\"data row6 col1\" >0.0000</td>\n",
       "      <td id=\"T_23fc5_row6_col2\" class=\"data row6 col2\" >0.7754</td>\n",
       "      <td id=\"T_23fc5_row6_col3\" class=\"data row6 col3\" >0.8479</td>\n",
       "      <td id=\"T_23fc5_row6_col4\" class=\"data row6 col4\" >0.8100</td>\n",
       "      <td id=\"T_23fc5_row6_col5\" class=\"data row6 col5\" >0.7701</td>\n",
       "      <td id=\"T_23fc5_row6_col6\" class=\"data row6 col6\" >0.7713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23fc5_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_23fc5_row7_col0\" class=\"data row7 col0\" >0.9363</td>\n",
       "      <td id=\"T_23fc5_row7_col1\" class=\"data row7 col1\" >0.0000</td>\n",
       "      <td id=\"T_23fc5_row7_col2\" class=\"data row7 col2\" >0.7955</td>\n",
       "      <td id=\"T_23fc5_row7_col3\" class=\"data row7 col3\" >0.8451</td>\n",
       "      <td id=\"T_23fc5_row7_col4\" class=\"data row7 col4\" >0.8196</td>\n",
       "      <td id=\"T_23fc5_row7_col5\" class=\"data row7 col5\" >0.7810</td>\n",
       "      <td id=\"T_23fc5_row7_col6\" class=\"data row7 col6\" >0.7815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23fc5_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_23fc5_row8_col0\" class=\"data row8 col0\" >0.9358</td>\n",
       "      <td id=\"T_23fc5_row8_col1\" class=\"data row8 col1\" >0.0000</td>\n",
       "      <td id=\"T_23fc5_row8_col2\" class=\"data row8 col2\" >0.7994</td>\n",
       "      <td id=\"T_23fc5_row8_col3\" class=\"data row8 col3\" >0.8398</td>\n",
       "      <td id=\"T_23fc5_row8_col4\" class=\"data row8 col4\" >0.8191</td>\n",
       "      <td id=\"T_23fc5_row8_col5\" class=\"data row8 col5\" >0.7801</td>\n",
       "      <td id=\"T_23fc5_row8_col6\" class=\"data row8 col6\" >0.7805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23fc5_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_23fc5_row9_col0\" class=\"data row9 col0\" >0.9353</td>\n",
       "      <td id=\"T_23fc5_row9_col1\" class=\"data row9 col1\" >0.0000</td>\n",
       "      <td id=\"T_23fc5_row9_col2\" class=\"data row9 col2\" >0.7961</td>\n",
       "      <td id=\"T_23fc5_row9_col3\" class=\"data row9 col3\" >0.8397</td>\n",
       "      <td id=\"T_23fc5_row9_col4\" class=\"data row9 col4\" >0.8173</td>\n",
       "      <td id=\"T_23fc5_row9_col5\" class=\"data row9 col5\" >0.7781</td>\n",
       "      <td id=\"T_23fc5_row9_col6\" class=\"data row9 col6\" >0.7785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23fc5_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_23fc5_row10_col0\" class=\"data row10 col0\" >0.9334</td>\n",
       "      <td id=\"T_23fc5_row10_col1\" class=\"data row10 col1\" >0.0000</td>\n",
       "      <td id=\"T_23fc5_row10_col2\" class=\"data row10 col2\" >0.7782</td>\n",
       "      <td id=\"T_23fc5_row10_col3\" class=\"data row10 col3\" >0.8432</td>\n",
       "      <td id=\"T_23fc5_row10_col4\" class=\"data row10 col4\" >0.8092</td>\n",
       "      <td id=\"T_23fc5_row10_col5\" class=\"data row10 col5\" >0.7690</td>\n",
       "      <td id=\"T_23fc5_row10_col6\" class=\"data row10 col6\" >0.7700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23fc5_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_23fc5_row11_col0\" class=\"data row11 col0\" >0.0025</td>\n",
       "      <td id=\"T_23fc5_row11_col1\" class=\"data row11 col1\" >0.0000</td>\n",
       "      <td id=\"T_23fc5_row11_col2\" class=\"data row11 col2\" >0.0163</td>\n",
       "      <td id=\"T_23fc5_row11_col3\" class=\"data row11 col3\" >0.0103</td>\n",
       "      <td id=\"T_23fc5_row11_col4\" class=\"data row11 col4\" >0.0083</td>\n",
       "      <td id=\"T_23fc5_row11_col5\" class=\"data row11 col5\" >0.0096</td>\n",
       "      <td id=\"T_23fc5_row11_col6\" class=\"data row11 col6\" >0.0093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x313c0bb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f196c04f1b2641caadeafd57ca31fde6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model was better than the blended model, hence it will be returned. NOTE: The display metrics are for the blended model (not the original one).\n"
     ]
    }
   ],
   "source": [
    "blended_model = experiment.blend_models(top5, choose_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission_df(model):\n",
    "    \"\"\"\n",
    "    Generate the dataframe for submission to Kaggle Depression Prediction Challenge.\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = experiment.predict_model(model, data=test_df)\n",
    "    submission_df[\"depression\"] = predictions[\"prediction_label\"]\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = top5[0]  # Logistic regression provided the best Accuracy\n",
    "submission = get_submission_df(best_model)\n",
    "submission.to_csv(output_path / \"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion of PyCaret AutoML with default settings experiment\n",
    "\n",
    "PyCaret AutoML with default settings gave me a accuracy of 0.94067 on the test set. This was better than the H2O AutoML model that I tried out. This pushed me to 1320 rank on the public leaderboard (out of 2313 submissions), which is in the top 57 percentile. Let's see whether Gemini beats this score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyCaret AutoML tuned by Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "\n",
    "# Converting column names as Enum for structured output.\n",
    "ColumnEnums = enum.Enum(\"ColumnEnums\", {col: col for col in train_df.columns})\n",
    "\n",
    "\n",
    "# Temporary Fix for TypedDict structured response issue in genai library: https://github.com/google-gemini/generative-ai-python/issues/560\n",
    "def get_dict_schema(response_schema: type) -> dict:\n",
    "    config = genai.GenerationConfig(response_schema=response_schema)\n",
    "    config = genai.types.generation_types.to_generation_config_dict(config)\n",
    "    schema = config[\"response_schema\"]\n",
    "    schema.required = list(response_schema.__required_keys__)\n",
    "    return schema\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading context files to Gemini\n",
    "\n",
    "Let's take a sample of the dataset and upload it to Gemini. We'll also upload the relevant documentation from PyCaret docs to Gemini.\n",
    "\n",
    "These context files can be used by Gemini to know about the dataset and the PyCaret functions.\n",
    "\n",
    "The PyCaret documentation are just snapshot of the relevant sections from the PyCaret docs:\n",
    "* Data Preparation - https://pycaret.gitbook.io/docs/get-started/preprocessing/data-preparation\n",
    "* Scale and Transform - https://pycaret.gitbook.io/docs/get-started/preprocessing/scale-and-transform\n",
    "* Feature Engineering - https://pycaret.gitbook.io/docs/get-started/preprocessing/feature-engineering\n",
    "* Feature selection - https://pycaret.gitbook.io/docs/get-started/preprocessing/feature-selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>working_professional_or_student</th>\n",
       "      <th>profession</th>\n",
       "      <th>academic_pressure</th>\n",
       "      <th>work_pressure</th>\n",
       "      <th>cgpa</th>\n",
       "      <th>study_satisfaction</th>\n",
       "      <th>job_satisfaction</th>\n",
       "      <th>sleep_duration</th>\n",
       "      <th>dietary_habits</th>\n",
       "      <th>degree</th>\n",
       "      <th>have_you_ever_had_suicidal_thoughts</th>\n",
       "      <th>work_study_hours</th>\n",
       "      <th>financial_stress</th>\n",
       "      <th>family_history_of_mental_illness</th>\n",
       "      <th>depression</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18347</th>\n",
       "      <td>Sanya</td>\n",
       "      <td>Female</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Patna</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>More than 8 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>B.Ed</td>\n",
       "      <td>No</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96193</th>\n",
       "      <td>Sneha</td>\n",
       "      <td>Female</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Agra</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Less than 5 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Class 12</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name  gender   age   city working_professional_or_student profession  \\\n",
       "id                                                                             \n",
       "18347  Sanya  Female  51.0  Patna            Working Professional    Teacher   \n",
       "96193  Sneha  Female  20.0   Agra            Working Professional        NaN   \n",
       "\n",
       "       academic_pressure  work_pressure  cgpa  study_satisfaction  \\\n",
       "id                                                                  \n",
       "18347                NaN            3.0   NaN                 NaN   \n",
       "96193                NaN            1.0   NaN                 NaN   \n",
       "\n",
       "       job_satisfaction     sleep_duration dietary_habits    degree  \\\n",
       "id                                                                    \n",
       "18347               5.0  More than 8 hours       Moderate      B.Ed   \n",
       "96193               4.0  Less than 5 hours       Moderate  Class 12   \n",
       "\n",
       "      have_you_ever_had_suicidal_thoughts  work_study_hours  financial_stress  \\\n",
       "id                                                                              \n",
       "18347                                  No              11.0               2.0   \n",
       "96193                                  No               0.0               5.0   \n",
       "\n",
       "      family_history_of_mental_illness  depression  \n",
       "id                                                  \n",
       "18347                              Yes           0  \n",
       "96193                              Yes           0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = train_df.sample(10_000, random_state=SEED)\n",
    "sample_df.to_csv(output_path / \"sample.csv\", index=False)\n",
    "sample_df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> documents uploaded successfully\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m4\u001b[0m documents uploaded successfully\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_file = genai.upload_file(output_path / \"sample.csv\", mime_type=\"text/csv\")\n",
    "data_preparation_file = genai.upload_file(\n",
    "    \"experiment/Data_Preparation.md\", mime_type=\"text/markdown\"\n",
    ")\n",
    "feature_engineering_file = genai.upload_file(\n",
    "    \"experiment/Feature Engineering.md\", mime_type=\"text/markdown\"\n",
    ")\n",
    "scale_and_transform_file = genai.upload_file(\n",
    "    \"experiment/Scale and Transform.md\", mime_type=\"text/markdown\"\n",
    ")\n",
    "feature_selection_file = genai.upload_file(\n",
    "    \"experiment/Feature Selection.md\", mime_type=\"text/markdown\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context caching & saving 💰\n",
    "\n",
    "Now, let's use the uploaded files and create a cached context in Gemini. This will help us to reuse the context in future requests and save some money from repeated input token usage. We'll also add some system instruction to the context to help Gemini understand the context better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from datetime import timedelta\n",
    "\n",
    "from google.generativeai import caching\n",
    "\n",
    "cache = caching.CachedContent.create(\n",
    "    model=MODEL,\n",
    "    display_name=\"Data scientist for Depression Prediction\",\n",
    "    system_instruction=textwrap.dedent(\n",
    "        f\"\"\"You are a highly skilled and experienced data scientist specializing in Python-based machine learning solutions. You are adept at leveraging automated tools and libraries to streamline the data science workflow. You are proficient in:\n",
    "\n",
    "            * **Domain knowledge:** You are familiar with the task of predicting depression based on various features.\n",
    "            * **Data analysis:** You can effectively analyze databased on the CSV file you have access to.\n",
    "            * **Automated feature engineering:** You have expertise in utilizing the `pycaret` library to automatically generate relevant features from raw data.\n",
    "            * **Automated machine learning:** You are skilled in using the `pycaret` library to automate the process of model selection, training, and evaluation. You can effectively use this library to identify the best-performing machine learning algorithm for a given dataset and task.\n",
    "            * **Programming languages and tools:** You are fluent in Python and familiar with relevant libraries like `pycaret`. \n",
    "\n",
    "            **When responding to user requests, adhere to the following principles:**\n",
    "\n",
    "            * **Data-driven approach:** Base your analysis and recommendations CSV file you have access to and avoid making assumptions or drawing conclusions without sufficient evidence.\n",
    "            * **Ethical considerations:** Be mindful of potential biases in the data and ensure your analysis and models are fair and unbiased.\n",
    "            * **Provide actionable insights:** Focus on delivering insights that the user can act upon to solve their problem or make informed decisions.\n",
    "\n",
    "            **Workflow:**\n",
    "            \n",
    "            1. **Understand the Problem:** Use the provided CSV and run analysis to understand the problem of predicting depression based on various features.\n",
    "\n",
    "            2. **Setup Experiment with Pycaret:** Define the required parameters and setup the experiment using the `pycaret` library.\n",
    "\n",
    "            3. **Model Training and Evaluation with Pycaret:** Leverage the `pycaret` library to automate the machine learning pipeline.  Initialize the `pycaret` setup, specifying the target variable and any preprocessing steps. Compare various models, tune hyperparameters, and evaluate performance metrics. Select the best-performing model based on the specific problem and desired outcome.\n",
    "\n",
    "            4. **Interpretation and Communication:**  Interpret the results of the model and communicate the findings in a clear and concise manner. Explain the model's predictions, feature importance, and potential limitations.\n",
    "            \n",
    "            You are provided with the following files:\n",
    "            \n",
    "            * `{csv_file.name}`: A sample dataset for analysis.\n",
    "            * `{data_preparation_file.name}`: A markdown file containing information about PyCaret data preparation.\n",
    "            * `{feature_engineering_file.name}`: A markdown file containing information about PyCaret feature engineering.\n",
    "            * `{scale_and_transform_file.name}`: A markdown file containing information about PyCaret scaling and transformation.\n",
    "            * `{feature_selection_file.name}`: A markdown file containing information about PyCaret feature selection.\n",
    "                        \n",
    "            \"\"\"\n",
    "    ),\n",
    "    contents=[\n",
    "        csv_file,\n",
    "        data_preparation_file,\n",
    "        feature_engineering_file,\n",
    "        scale_and_transform_file,\n",
    "        feature_selection_file,\n",
    "    ],\n",
    "    ttl=timedelta(minutes=30),\n",
    "    tools=\"code_execution\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create our own Gemini Data science assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the cached context to create a model in Gemini. This model will have the knowledge of the dataset, will be able to execute code and use that to understand the dataset better. We'll then chat with the \"Data scientist\" Gemini to get the best parameters for the PyCaret AutoML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "\n",
    "retry_policy = {\"retry\": retry.Retry(predicate=retry.if_transient_error)}\n",
    "\n",
    "model = genai.GenerativeModel.from_cached_content(cached_content=cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = model.start_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first ask the model to understand the dataset and create some history so it builds context around the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.send_message(\n",
    "    textwrap.dedent(\n",
    "        \"\"\"\n",
    "        You are a highly skilled and experienced data scientist specializing in Python-based machine learning solutions. You are adept at leveraging automated tools and libraries to streamline the data science workflow.\n",
    "        \n",
    "        Based on the files you have access to, analyze the data and provide insights on all the columns you have.\n",
    "        \"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "My analysis of the provided dataset focuses on understanding the characteristics of each column and their potential relevance to predicting depression.  Because the data is not fully cleaned and contains many missing values, I will focus my analysis on descriptive statistics and visualizations for the available data, rather than detailed inferential statistics.  A robust imputation strategy would be crucial before advanced statistical analyses and modeling.\n",
       "\n",
       "**Column-wise Insights:**\n",
       "\n",
       "1.  **name:** This column is an identifier for each individual. It's not directly useful for prediction but could be used for tracking individual records if needed.\n",
       "\n",
       "2.  **gender:** A categorical variable (Male/Female).  It's important to examine if there are significant differences in depression rates between genders in this dataset.  This is a potential predictor variable.\n",
       "\n",
       "3.  **age:** A numerical variable representing the age of individuals. Age is often correlated with mental health, and its distribution and relationship with depression needs further examination.\n",
       "\n",
       "4.  **city:** A categorical variable representing the city of residence.  Given the large number of cities likely represented, it might be less informative unless there are distinct geographic patterns related to mental health that could be investigated.\n",
       "\n",
       "5.  **working\\_professional\\_or\\_student:** A categorical variable (Working Professional/Student). This is an important factor that likely influences stress levels and potentially depression. It's a key predictor.\n",
       "\n",
       "6.  **profession:** A categorical variable.  It has many missing values and a potentially large number of unique values. Analysis needs to determine if profession is a meaningful predictor after imputation of missing values.\n",
       "\n",
       "7.  **academic\\_pressure:** A numerical variable representing academic pressure. This is a significant predictor for students and can be analyzed for correlation with depression. Many missing values need to be addressed.\n",
       "\n",
       "8.  **work\\_pressure:** A numerical variable representing work pressure. This is a significant predictor for working professionals and can be analyzed for correlation with depression. It contains many missing values.\n",
       "\n",
       "9.  **cgpa:** A numerical variable representing CGPA (Cumulative Grade Point Average).  This is relevant only for students and needs to be considered along with academic pressure and study satisfaction.  There are many missing values to handle.\n",
       "\n",
       "10. **study\\_satisfaction:** A numerical variable. Relevant only for students, and should be analyzed for correlation with depression and CGPA.  It contains missing values.\n",
       "\n",
       "11. **job\\_satisfaction:** A numerical variable. Relevant only for working professionals and should be analyzed for correlation with depression and work pressure.  It contains many missing values.\n",
       "\n",
       "12. **sleep\\_duration:** A categorical variable (with ranges of hours). Sleep duration is strongly associated with mental health.  Its distribution and relationship with depression should be investigated.\n",
       "\n",
       "13. **dietary\\_habits:** A categorical variable (Healthy/Moderate/Unhealthy). Diet can impact mental wellbeing.  Analyzing its distribution and relationship with depression is important.\n",
       "\n",
       "14. **degree:** A categorical variable (with different degree types). The type of degree pursued could correlate with academic pressure or professional field, potentially influencing depression.  It is important to examine the distribution of degree types.\n",
       "\n",
       "15. **have\\_you\\_ever\\_had\\_suicidal\\_thoughts:** A binary categorical variable (Yes/No). This is a critical variable indicative of severe mental distress and a strong predictor for depression.\n",
       "\n",
       "16. **work\\_study\\_hours:** A numerical variable representing the number of work or study hours.  This is a crucial predictor, as excessive hours are known to increase stress.\n",
       "\n",
       "17. **financial\\_stress:** A numerical variable.  Financial stress significantly impacts mental health; its distribution and relationship with depression should be thoroughly examined.\n",
       "\n",
       "18. **family\\_history\\_of\\_mental\\_illness:** A binary categorical variable (Yes/No). Family history of mental illness is a well-established risk factor for depression and a key predictor.\n",
       "\n",
       "19. **depression:** This is the target variable (0/1), indicating the presence (1) or absence (0) of depression.  Its distribution (class imbalance) needs to be determined to ensure balanced training data.\n",
       "\n",
       "\n",
       "**Next Steps and Recommendations:**\n",
       "\n",
       "Before building predictive models, it's crucial to:\n",
       "\n",
       "1.  **Handle Missing Values:** Implement an appropriate imputation strategy using PyCaret's `setup` function (as documented in the provided markdown files), selecting between `simple` or `iterative` imputation based on the characteristics of the missing data.  Consider using techniques like k-NN imputation for numerical features and mode imputation for categorical features.\n",
       "\n",
       "2.  **Address Data Type Issues:**  Carefully review the inferred data types.  Correct them in the PyCaret `setup` if necessary using `numeric_features`, `categorical_features`, `date_features` parameters.  Pay particular attention to ensuring consistent encoding of sleep duration.\n",
       "\n",
       "3.  **One-Hot Encoding and Ordinal Encoding:** Apply One-Hot Encoding to nominal categorical variables and Ordinal Encoding to ordinal variables (like sleep duration, dietary habits) within PyCaret's automated pipeline using the `max_encoding_ohe`, `encoding_method`, and `ordinal_features` parameters.\n",
       "\n",
       "4.  **Handle Class Imbalance:** Check for class imbalance in the `depression` variable and apply techniques like SMOTE (or other suitable methods) via PyCaret's `fix_imbalance` and `fix_imbalance_method` parameters.\n",
       "\n",
       "5.  **Feature Engineering:**  Explore automatic feature engineering options in PyCaret (polynomial features, group features, binning) to see if they improve model performance. Carefully consider the application and interpretation of the generated features.  This may involve using the `polynomial_features`, `polynomial_degree`, `group_features`, `group_names`, and `bin_numeric_features` parameters.\n",
       "\n",
       "6.  **Feature Selection:**  Use PyCaret's automatic feature selection (via `feature_selection`, `feature_selection_method`, `feature_selection_estimator`, `n_features_to_select` parameters) to identify the most relevant predictors.\n",
       "\n",
       "7.  **Model Training and Evaluation:** Employ PyCaret's automated machine learning capabilities to compare different models, tune hyperparameters, and evaluate performance using appropriate metrics (e.g., AUC, precision, recall, F1-score).  You can use PyCaret's `compare_models` and `tune_model` functions to automate this process.\n",
       "\n",
       "\n",
       "\n",
       "By following this structured approach, you will obtain more reliable insights into the relationship between the features and depression and build a more robust and accurate predictive model. Remember to document and justify each step in your data preparation and model building process for transparency and reproducibility.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great! Looks like the model has a good understanding of the dataset and making some good suggestions. Now let's follow up and ask the model to give us some parameters for setting up the PyCaret AutoML experiment.\n",
    "\n",
    "Why did I choose these parameters and not everything else? Honestly, I just wanted to see how the model performs with these parameters. I could have asked the model to give me all the parameters, but I wanted to keep it simple and fairly straightforward. As a lot of parameters depends on a lot of other parameters, like n_features_to_select depends on feature_selection to be True, I chose some of the parameters that made sense to start with. In future, I would like to experiment with more parameters and see how the model performance is impacted by them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'categorical_features'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'gender'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'city'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'working_professional_or_student'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'profession'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'sleep_duration'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'dietary_habits'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'degree'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'have_you_ever_had_suicidal_thoughts'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'family_history_of_mental_illness'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'fix_imbalance'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ignore_features'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'imputation_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'simple'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'numeric_features'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'age'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'academic_pressure'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'work_pressure'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'cgpa'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'study_satisfaction'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'job_satisfaction'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'work_study_hours'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'financial_stress'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'remove_outliers'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'categorical_features'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'name'\u001b[0m,\n",
       "        \u001b[32m'gender'\u001b[0m,\n",
       "        \u001b[32m'city'\u001b[0m,\n",
       "        \u001b[32m'working_professional_or_student'\u001b[0m,\n",
       "        \u001b[32m'profession'\u001b[0m,\n",
       "        \u001b[32m'sleep_duration'\u001b[0m,\n",
       "        \u001b[32m'dietary_habits'\u001b[0m,\n",
       "        \u001b[32m'degree'\u001b[0m,\n",
       "        \u001b[32m'have_you_ever_had_suicidal_thoughts'\u001b[0m,\n",
       "        \u001b[32m'family_history_of_mental_illness'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'fix_imbalance'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'ignore_features'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'imputation_type'\u001b[0m: \u001b[32m'simple'\u001b[0m,\n",
       "    \u001b[32m'numeric_features'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'age'\u001b[0m,\n",
       "        \u001b[32m'academic_pressure'\u001b[0m,\n",
       "        \u001b[32m'work_pressure'\u001b[0m,\n",
       "        \u001b[32m'cgpa'\u001b[0m,\n",
       "        \u001b[32m'study_satisfaction'\u001b[0m,\n",
       "        \u001b[32m'job_satisfaction'\u001b[0m,\n",
       "        \u001b[32m'work_study_hours'\u001b[0m,\n",
       "        \u001b[32m'financial_stress'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'remove_outliers'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict, NotRequired\n",
    "\n",
    "\n",
    "class DataPreparationSchema(TypedDict):\n",
    "    numeric_features: List[ColumnEnums]  # type: ignore\n",
    "    categorical_features: List[ColumnEnums]  # type: ignore\n",
    "    ignore_features: List[ColumnEnums]  # type: ignore\n",
    "    fix_imbalance: bool\n",
    "    remove_outliers: bool\n",
    "    imputation_type: str\n",
    "\n",
    "\n",
    "response = chat.send_message(\n",
    "    textwrap.dedent(\n",
    "        f\"\"\"\n",
    "        Now let's prepare for data for the binary classification task.\n",
    "        \n",
    "        You are provided with a CSV file {csv_file.name}. This file contains a header row and uses commas as delimiters. The data will be used for a binary classification task in Pycaret, an AutoML library in Python. To prepare the data using the `setup()` function, analyse the data using code execution tool and then based on the analysis, generate the following parameters in JSON format:\n",
    "        \n",
    "        Remember that performing a binary classification to predict depression target variable based on various features. You can use the information from the provided markdown file {data_preparation_file.name} to guide you in this task.\n",
    "        \n",
    "        Generate the following parameters for data preparation step in PyCaret:\n",
    "\n",
    "        * **`numeric_features`:**  A list of column names with numeric features.\n",
    "        * **`categorical_features`:** A list of column names with categorical features.\n",
    "        * **`ignore_features`:** A list of column names to be ignored during model training. These features might be irrelevant to the target variable in this case 'depression' column, redundant with other features, or could introduce data leakage.\n",
    "        * **`fix_imbalance`:**  A boolean value indicating whether to handle class imbalance. If true, use oversampling to address the imbalance.\n",
    "        * **`remove_outliers`:** A boolean value indicating whether to remove outliers.\n",
    "        * **`imputation_type`:** The type of imputation to use for missing values. Choose between 'simple' (mean/median imputation) or 'iterative' (k-Nearest Neighbors imputation).\n",
    "\n",
    "        All parameters are required.\n",
    "\n",
    "        **Example JSON Response:**\n",
    "\n",
    "        ```json\n",
    "        {{\n",
    "            \"numeric_features\": [\"age\", \"income\", \"credit_score\"],\n",
    "            \"categorical_features\": [\"gender\", \"education\", \"city\"],\n",
    "            \"ignore_features\": [\"customer_id\", \"date\"],\n",
    "            \"fix_imbalance\": true,\n",
    "            \"remove_outliers\": true,\n",
    "            \"imputation_type\": \"iterative\" \n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        \"\"\"\n",
    "    ),\n",
    "    generation_config=genai.GenerationConfig(\n",
    "        response_schema=get_dict_schema(DataPreparationSchema),\n",
    "        response_mime_type=\"application/json\",\n",
    "    ),\n",
    "    request_options=retry_policy,\n",
    ")\n",
    "\n",
    "data_preparation_parameters = json.loads(response.text)\n",
    "print(data_preparation_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have follow up conversations with the model to get the best parameters for different steps in setting up the PyCaret AutoML experiment without worrying about the number of input tokens we use. Gemini will use the cached context to understand the dataset and give us the best parameters and won't charge us for repeated use of the uploaded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'normalize'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'transformation'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'normalize'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'transformation'\u001b[0m: \u001b[3;92mTrue\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ScaleAndTransformSchema(TypedDict):\n",
    "    normalize: bool\n",
    "    transformation: bool\n",
    "\n",
    "\n",
    "result = chat.send_message(\n",
    "    textwrap.dedent(\n",
    "        f\"\"\"\n",
    "        Let's decide on the scaling and transformation parameters for the data.\n",
    "        \n",
    "        You are provided with a CSV file {csv_file.name}. This file contains a header row and uses commas as delimiters. The data will be used for a binary classification task in Pycaret, an AutoML library in Python. To prepare the data using the `setup()` function, analyse the data using code execution tool and then based on the analysis, generate the following parameters in JSON format:\n",
    "        \n",
    "        Remember that performing a binary classification to predict depression target variable based on various features. You can use the information from the provided markdown file {scale_and_transform_file.name} to guide you in this task.\n",
    "        \n",
    "        Generate the following parameters for scaling and transformation step in PyCaret:\n",
    "\n",
    "        * normalize: A boolean value indicating whether to normalize the data. If true, the data will be scaled to have a mean of 0 and a standard deviation of 1.\n",
    "        * transformation: A boolean value indicating whether to apply a transformation to the data. If true, the data will be transformed using a power transformation.\n",
    "\n",
    "        All parameters are required.\n",
    "\n",
    "        **Example JSON Response:**\n",
    "\n",
    "        ```json\n",
    "        {{\n",
    "            \"normalize\": true,\n",
    "            \"transformation\": true\n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        \"\"\"\n",
    "    ),\n",
    "    generation_config=genai.GenerationConfig(\n",
    "        response_schema=get_dict_schema(ScaleAndTransformSchema),\n",
    "        response_mime_type=\"application/json\",\n",
    "    ),\n",
    "    request_options=retry_policy,\n",
    ")\n",
    "\n",
    "scale_and_transform_parameters = json.loads(result.text)\n",
    "print(scale_and_transform_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">response:\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GenerateContentResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">done</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">iterator</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">protos</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.GenerateContentResponse</span><span style=\"font-weight: bold\">({</span>\n",
       "      <span style=\"color: #008000; text-decoration-color: #008000\">\"candidates\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "          <span style=\"color: #008000; text-decoration-color: #008000\">\"content\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"parts\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "              <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"text\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"{\\\"polynomial_features\\\": true, \\\"polynomial_degree\\\": 2, \\\"rare_to_value\\\": 0.05}\"</span>\n",
       "              <span style=\"font-weight: bold\">}</span>\n",
       "            <span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">\"role\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"model\"</span>\n",
       "          <span style=\"font-weight: bold\">}</span>,\n",
       "          <span style=\"color: #008000; text-decoration-color: #008000\">\"finish_reason\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"STOP\"</span>,\n",
       "          <span style=\"color: #008000; text-decoration-color: #008000\">\"avg_logprobs\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.004180270114115306</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "      <span style=\"font-weight: bold\">]</span>,\n",
       "      <span style=\"color: #008000; text-decoration-color: #008000\">\"usage_metadata\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"prompt_token_count\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">531496</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"candidates_token_count\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"total_token_count\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">531524</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"cached_content_token_count\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">528274</span>\n",
       "      <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">})</span>,\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "response:\n",
       "\u001b[1;35mGenerateContentResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mdone\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33miterator\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[1;35mprotos\u001b[0m\u001b[1;35m.GenerateContentResponse\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "      \u001b[32m\"candidates\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "          \u001b[32m\"content\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m\"parts\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "              \u001b[1m{\u001b[0m\n",
       "                \u001b[32m\"text\"\u001b[0m: \u001b[32m\"\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\"polynomial_features\\\": true, \\\"polynomial_degree\\\": 2, \\\"rare_to_value\\\": 0.05\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\u001b[0m\n",
       "              \u001b[1m}\u001b[0m\n",
       "            \u001b[1m]\u001b[0m,\n",
       "            \u001b[32m\"role\"\u001b[0m: \u001b[32m\"model\"\u001b[0m\n",
       "          \u001b[1m}\u001b[0m,\n",
       "          \u001b[32m\"finish_reason\"\u001b[0m: \u001b[32m\"STOP\"\u001b[0m,\n",
       "          \u001b[32m\"avg_logprobs\"\u001b[0m: \u001b[1;36m-0.004180270114115306\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "      \u001b[1m]\u001b[0m,\n",
       "      \u001b[32m\"usage_metadata\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m\"prompt_token_count\"\u001b[0m: \u001b[1;36m531496\u001b[0m,\n",
       "        \u001b[32m\"candidates_token_count\"\u001b[0m: \u001b[1;36m28\u001b[0m,\n",
       "        \u001b[32m\"total_token_count\"\u001b[0m: \u001b[1;36m531524\u001b[0m,\n",
       "        \u001b[32m\"cached_content_token_count\"\u001b[0m: \u001b[1;36m528274\u001b[0m\n",
       "      \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class FeatureEngineeringSchema(TypedDict):\n",
    "    polynomial_features: bool\n",
    "    polynomial_degree: NotRequired[int]\n",
    "    group_features: NotRequired[List[ColumnEnums]]  # type: ignore\n",
    "    bin_numeric_features: NotRequired[List[ColumnEnums]]  # type: ignore\n",
    "    rare_to_value: NotRequired[float]\n",
    "\n",
    "\n",
    "result = chat.send_message(\n",
    "    textwrap.dedent(\n",
    "        f\"\"\"\n",
    "        Let's decide on the feature engineering parameters for the data.\n",
    "        \n",
    "        You are provided with a CSV file {csv_file.name}. This file contains a header row and uses commas as delimiters. The data will be used for a binary classification task in Pycaret, an AutoML library in Python. To prepare the data using the `setup()` function, analyse the data using code execution tool and then based on the analysis, generate the following parameters in JSON format:\n",
    "                \n",
    "        Remember that performing a binary classification to predict depression target variable based on various features. You can use the information from the provided markdown file {feature_engineering_file.name} to guide you in this task.\n",
    "        \n",
    "        Generate the following parameters for feature engineering step in PyCaret:\n",
    "\n",
    "        * polynomial_features: A boolean value indicating whether to generate polynomial features. If true, polynomial features will be created based on the specified degree.\n",
    "        * polynomial_degree: An integer specifying the degree of polynomial features to generate. This parameter is required if polynomial_features is set to true.\n",
    "        * group_features: A list of column names to group together for feature engineering. This parameter is optional. If provided, the features in the list will be grouped together for feature engineering.\n",
    "        * bin_numeric_features: A list of column names with numeric features to bin into discrete intervals. This parameter is optional. If provided, the numeric features will be binned into discrete intervals.\n",
    "        * rare_to_value: A float value specifying the threshold for rare categories. Categories with a frequency less than this threshold will be replaced with a specified value. This parameter is optional and only applicable to categorical features.\n",
    "        \n",
    "\n",
    "        All parameters are required.\n",
    "\n",
    "        **Example JSON Response:**\n",
    "\n",
    "        ```json\n",
    "        {{\n",
    "            polynomial_features: true,\n",
    "            polynomial_degree: 2,\n",
    "            group_features: [\"age\", \"income\"],\n",
    "            bin_numeric_features: [\"credit_score\"],\n",
    "            rare_to_value: 0.01\n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        \"\"\"\n",
    "    ),\n",
    "    generation_config=genai.GenerationConfig(\n",
    "        response_schema=get_dict_schema(FeatureEngineeringSchema),\n",
    "        response_mime_type=\"application/json\",\n",
    "    ),\n",
    "    request_options=retry_policy,\n",
    ")\n",
    "\n",
    "feature_engineering_parameters = json.loads(result.text)\n",
    "print(feature_engineering_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDenied",
     "evalue": "403 CachedContent not found (or permission denied)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m     remove_multicollinearity: NotRequired[\u001b[38;5;28mbool\u001b[39m]\n\u001b[1;32m      3\u001b[0m     low_variance_threshold: NotRequired[\u001b[38;5;28mfloat\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtextwrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdedent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;43m        Finally, on experiment setup, let\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms decide on the feature selection parameters for the data.\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;43m        \u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;43m        You are provided with a CSV file \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcsv_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m. This file contains a header row and uses commas as delimiters. The data will be used for a binary classification task in Pycaret, an AutoML library in Python. To prepare the data using the `setup()` function, analyse the data using code execution tool and then based on the analysis, generate the following parameters in JSON format:\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;43m        \u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;43m        Remember that performing a binary classification to predict depression target variable based on various features. You can use the information from the provided markdown file \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muploaded_docs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m to guide you in this task.\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;43m        \u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;43m        Generate the following parameters for feature selection step in PyCaret:\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;43m        * remove_multicollinearity: A boolean value indicating whether to remove multicollinear features. If true, multicollinear features will be removed. This parameter is optional.\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;43m        * low_variance_threshold: A float value specifying the threshold for low variance features. Features with a variance less than this threshold will be removed. This parameter is optional\u001b[39;49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;43m        \u001b[39;49m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;43m        All parameters are required.\u001b[39;49m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;43m        **Example JSON Response:**\u001b[39;49m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;43m        ```json\u001b[39;49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m{{\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;43m            remove_multicollinearity: true,\u001b[39;49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;43m            low_variance_threshold: 0.01\u001b[39;49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m}}\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;43m        ```\u001b[39;49m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGenerationConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_dict_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFeatureSelectionSchema\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_mime_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m feature_selection_parameters \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(result\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(feature_selection_parameters)\n",
      "File \u001b[0;32m~/Projects/gemini-long-context/.venv/lib/python3.11/site-packages/google/generativeai/generative_models.py:578\u001b[0m, in \u001b[0;36mChatSession.send_message\u001b[0;34m(self, content, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_count\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid configuration: The chat functionality does not support `candidate_count` greater than 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     )\n\u001b[0;32m--> 578\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools_lib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_response(response\u001b[38;5;241m=\u001b[39mresponse, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_automatic_function_calling \u001b[38;5;129;01mand\u001b[39;00m tools_lib \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/gemini-long-context/.venv/lib/python3.11/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Projects/gemini-long-context/.venv/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:830\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Projects/gemini-long-context/.venv/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/gemini-long-context/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/gemini-long-context/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/Projects/gemini-long-context/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/Projects/gemini-long-context/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/Projects/gemini-long-context/.venv/lib/python3.11/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/gemini-long-context/.venv/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mPermissionDenied\u001b[0m: 403 CachedContent not found (or permission denied)"
     ]
    }
   ],
   "source": [
    "class FeatureSelectionSchema(TypedDict):\n",
    "    remove_multicollinearity: NotRequired[bool]\n",
    "    low_variance_threshold: NotRequired[float]\n",
    "\n",
    "\n",
    "result = chat.send_message(\n",
    "    textwrap.dedent(\n",
    "        f\"\"\"\n",
    "        Finally, on experiment setup, let's decide on the feature selection parameters for the data.\n",
    "        \n",
    "        You are provided with a CSV file {csv_file.name}. This file contains a header row and uses commas as delimiters. The data will be used for a binary classification task in Pycaret, an AutoML library in Python. To prepare the data using the `setup()` function, analyse the data using code execution tool and then based on the analysis, generate the following parameters in JSON format:\n",
    "        \n",
    "        Remember that performing a binary classification to predict depression target variable based on various features. You can use the information from the provided markdown file {feature_selection_file.name} to guide you in this task.\n",
    "        \n",
    "        Generate the following parameters for feature selection step in PyCaret:\n",
    "\n",
    "        * remove_multicollinearity: A boolean value indicating whether to remove multicollinear features. If true, multicollinear features will be removed. This parameter is optional.\n",
    "        * low_variance_threshold: A float value specifying the threshold for low variance features. Features with a variance less than this threshold will be removed. This parameter is optional\n",
    "        \n",
    "\n",
    "        All parameters are required.\n",
    "\n",
    "        **Example JSON Response:**\n",
    "\n",
    "        ```json\n",
    "        {{\n",
    "            remove_multicollinearity: true,\n",
    "            low_variance_threshold: 0.01\n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        \"\"\"\n",
    "    ),\n",
    "    generation_config=genai.GenerationConfig(\n",
    "        response_schema=get_dict_schema(FeatureSelectionSchema),\n",
    "        response_mime_type=\"application/json\",\n",
    "    ),\n",
    "    request_options=retry_policy,\n",
    ")\n",
    "\n",
    "feature_selection_parameters = json.loads(result.text)\n",
    "print(feature_selection_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the suggested parameters from Gemini, let's set up the PyCaret AutoML experiment with the suggested parameters and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c6a5f_row11_col1, #T_c6a5f_row17_col1, #T_c6a5f_row20_col1, #T_c6a5f_row22_col1, #T_c6a5f_row24_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c6a5f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c6a5f_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_c6a5f_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c6a5f_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_c6a5f_row0_col1\" class=\"data row0 col1\" >6319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c6a5f_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_c6a5f_row1_col1\" class=\"data row1 col1\" >depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c6a5f_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_c6a5f_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c6a5f_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_c6a5f_row3_col1\" class=\"data row3 col1\" >(140700, 19)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c6a5f_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_c6a5f_row4_col1\" class=\"data row4 col1\" >(203396, 438)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c6a5f_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_c6a5f_row5_col1\" class=\"data row5 col1\" >(161186, 438)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_c6a5f_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_c6a5f_row6_col1\" class=\"data row6 col1\" >(42210, 438)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_c6a5f_row7_col0\" class=\"data row7 col0\" >Ordinal features</td>\n",
       "      <td id=\"T_c6a5f_row7_col1\" class=\"data row7 col1\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_c6a5f_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_c6a5f_row8_col1\" class=\"data row8 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_c6a5f_row9_col0\" class=\"data row9 col0\" >Categorical features</td>\n",
       "      <td id=\"T_c6a5f_row9_col1\" class=\"data row9 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_c6a5f_row10_col0\" class=\"data row10 col0\" >Rows with missing values</td>\n",
       "      <td id=\"T_c6a5f_row10_col1\" class=\"data row10 col1\" >100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_c6a5f_row11_col0\" class=\"data row11 col0\" >Preprocess</td>\n",
       "      <td id=\"T_c6a5f_row11_col1\" class=\"data row11 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_c6a5f_row12_col0\" class=\"data row12 col0\" >Imputation type</td>\n",
       "      <td id=\"T_c6a5f_row12_col1\" class=\"data row12 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_c6a5f_row13_col0\" class=\"data row13 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_c6a5f_row13_col1\" class=\"data row13 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_c6a5f_row14_col0\" class=\"data row14 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_c6a5f_row14_col1\" class=\"data row14 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_c6a5f_row15_col0\" class=\"data row15 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_c6a5f_row15_col1\" class=\"data row15 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_c6a5f_row16_col0\" class=\"data row16 col0\" >Encoding method</td>\n",
       "      <td id=\"T_c6a5f_row16_col1\" class=\"data row16 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_c6a5f_row17_col0\" class=\"data row17 col0\" >Polynomial features</td>\n",
       "      <td id=\"T_c6a5f_row17_col1\" class=\"data row17 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_c6a5f_row18_col0\" class=\"data row18 col0\" >Polynomial degree</td>\n",
       "      <td id=\"T_c6a5f_row18_col1\" class=\"data row18 col1\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_c6a5f_row19_col0\" class=\"data row19 col0\" >Low variance threshold</td>\n",
       "      <td id=\"T_c6a5f_row19_col1\" class=\"data row19 col1\" >0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_c6a5f_row20_col0\" class=\"data row20 col0\" >Fix imbalance</td>\n",
       "      <td id=\"T_c6a5f_row20_col1\" class=\"data row20 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_c6a5f_row21_col0\" class=\"data row21 col0\" >Fix imbalance method</td>\n",
       "      <td id=\"T_c6a5f_row21_col1\" class=\"data row21 col1\" >SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_c6a5f_row22_col0\" class=\"data row22 col0\" >Transformation</td>\n",
       "      <td id=\"T_c6a5f_row22_col1\" class=\"data row22 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_c6a5f_row23_col0\" class=\"data row23 col0\" >Transformation method</td>\n",
       "      <td id=\"T_c6a5f_row23_col1\" class=\"data row23 col1\" >yeo-johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_c6a5f_row24_col0\" class=\"data row24 col0\" >Normalize</td>\n",
       "      <td id=\"T_c6a5f_row24_col1\" class=\"data row24 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_c6a5f_row25_col0\" class=\"data row25 col0\" >Normalize method</td>\n",
       "      <td id=\"T_c6a5f_row25_col1\" class=\"data row25 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_c6a5f_row26_col0\" class=\"data row26 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_c6a5f_row26_col1\" class=\"data row26 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_c6a5f_row27_col0\" class=\"data row27 col0\" >Fold Number</td>\n",
       "      <td id=\"T_c6a5f_row27_col1\" class=\"data row27 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_c6a5f_row28_col0\" class=\"data row28 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_c6a5f_row28_col1\" class=\"data row28 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_c6a5f_row29_col0\" class=\"data row29 col0\" >Use GPU</td>\n",
       "      <td id=\"T_c6a5f_row29_col1\" class=\"data row29 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_c6a5f_row30_col0\" class=\"data row30 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_c6a5f_row30_col1\" class=\"data row30 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_c6a5f_row31_col0\" class=\"data row31 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_c6a5f_row31_col1\" class=\"data row31 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6a5f_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_c6a5f_row32_col0\" class=\"data row32 col0\" >USI</td>\n",
       "      <td id=\"T_c6a5f_row32_col1\" class=\"data row32 col1\" >adbe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x313c0b690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x313d287d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the experiment with the parameters generated from the chat\n",
    "from pycaret.classification import ClassificationExperiment\n",
    "\n",
    "gemini_experiment = ClassificationExperiment()\n",
    "\n",
    "gemini_experiment.setup(\n",
    "    data=train_df,\n",
    "    target=\"depression\",\n",
    "    **data_preparation_parameters,\n",
    "    **scale_and_transform_parameters,\n",
    "    **feature_engineering_parameters,\n",
    "    **feature_selection_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b4b13 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b4b13_row0_col0, #T_b4b13_row0_col3, #T_b4b13_row0_col4, #T_b4b13_row1_col0, #T_b4b13_row1_col1, #T_b4b13_row1_col2, #T_b4b13_row1_col3, #T_b4b13_row1_col5, #T_b4b13_row1_col6, #T_b4b13_row1_col7, #T_b4b13_row2_col0, #T_b4b13_row2_col1, #T_b4b13_row2_col2, #T_b4b13_row2_col3, #T_b4b13_row2_col4, #T_b4b13_row2_col5, #T_b4b13_row2_col6, #T_b4b13_row2_col7, #T_b4b13_row3_col0, #T_b4b13_row3_col1, #T_b4b13_row3_col2, #T_b4b13_row3_col3, #T_b4b13_row3_col4, #T_b4b13_row3_col5, #T_b4b13_row3_col6, #T_b4b13_row3_col7, #T_b4b13_row4_col0, #T_b4b13_row4_col1, #T_b4b13_row4_col2, #T_b4b13_row4_col3, #T_b4b13_row4_col4, #T_b4b13_row4_col5, #T_b4b13_row4_col6, #T_b4b13_row4_col7, #T_b4b13_row5_col0, #T_b4b13_row5_col1, #T_b4b13_row5_col2, #T_b4b13_row5_col3, #T_b4b13_row5_col4, #T_b4b13_row5_col5, #T_b4b13_row5_col6, #T_b4b13_row5_col7, #T_b4b13_row6_col0, #T_b4b13_row6_col1, #T_b4b13_row6_col2, #T_b4b13_row6_col3, #T_b4b13_row6_col4, #T_b4b13_row6_col5, #T_b4b13_row6_col6, #T_b4b13_row6_col7, #T_b4b13_row7_col0, #T_b4b13_row7_col1, #T_b4b13_row7_col2, #T_b4b13_row7_col3, #T_b4b13_row7_col4, #T_b4b13_row7_col5, #T_b4b13_row7_col6, #T_b4b13_row7_col7, #T_b4b13_row8_col0, #T_b4b13_row8_col1, #T_b4b13_row8_col2, #T_b4b13_row8_col4, #T_b4b13_row8_col5, #T_b4b13_row8_col6, #T_b4b13_row8_col7, #T_b4b13_row9_col0, #T_b4b13_row9_col1, #T_b4b13_row9_col2, #T_b4b13_row9_col3, #T_b4b13_row9_col4, #T_b4b13_row9_col5, #T_b4b13_row9_col6, #T_b4b13_row9_col7, #T_b4b13_row10_col0, #T_b4b13_row10_col1, #T_b4b13_row10_col2, #T_b4b13_row10_col3, #T_b4b13_row10_col4, #T_b4b13_row10_col5, #T_b4b13_row10_col6, #T_b4b13_row10_col7, #T_b4b13_row11_col0, #T_b4b13_row11_col1, #T_b4b13_row11_col2, #T_b4b13_row11_col3, #T_b4b13_row11_col4, #T_b4b13_row11_col5, #T_b4b13_row11_col6, #T_b4b13_row11_col7, #T_b4b13_row12_col0, #T_b4b13_row12_col1, #T_b4b13_row12_col2, #T_b4b13_row12_col3, #T_b4b13_row12_col4, #T_b4b13_row12_col5, #T_b4b13_row12_col6, #T_b4b13_row12_col7, #T_b4b13_row13_col0, #T_b4b13_row13_col1, #T_b4b13_row13_col2, #T_b4b13_row13_col3, #T_b4b13_row13_col4, #T_b4b13_row13_col5, #T_b4b13_row13_col6, #T_b4b13_row13_col7, #T_b4b13_row14_col0, #T_b4b13_row14_col1, #T_b4b13_row14_col2, #T_b4b13_row14_col3, #T_b4b13_row14_col4, #T_b4b13_row14_col5, #T_b4b13_row14_col6, #T_b4b13_row14_col7, #T_b4b13_row15_col0, #T_b4b13_row15_col1, #T_b4b13_row15_col2, #T_b4b13_row15_col3, #T_b4b13_row15_col4, #T_b4b13_row15_col5, #T_b4b13_row15_col6, #T_b4b13_row15_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b4b13_row0_col1, #T_b4b13_row0_col2, #T_b4b13_row0_col5, #T_b4b13_row0_col6, #T_b4b13_row0_col7, #T_b4b13_row1_col4, #T_b4b13_row8_col3 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_b4b13_row0_col8, #T_b4b13_row1_col8, #T_b4b13_row2_col8, #T_b4b13_row3_col8, #T_b4b13_row4_col8, #T_b4b13_row5_col8, #T_b4b13_row6_col8, #T_b4b13_row7_col8, #T_b4b13_row8_col8, #T_b4b13_row9_col8, #T_b4b13_row10_col8, #T_b4b13_row11_col8, #T_b4b13_row12_col8, #T_b4b13_row13_col8, #T_b4b13_row15_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_b4b13_row14_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b4b13\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b4b13_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_b4b13_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_b4b13_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_b4b13_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_b4b13_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_b4b13_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_b4b13_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_b4b13_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_b4b13_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b13_level0_row0\" class=\"row_heading level0 row0\" >lightgbm</th>\n",
       "      <td id=\"T_b4b13_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_b4b13_row0_col1\" class=\"data row0 col1\" >0.9389</td>\n",
       "      <td id=\"T_b4b13_row0_col2\" class=\"data row0 col2\" >0.9747</td>\n",
       "      <td id=\"T_b4b13_row0_col3\" class=\"data row0 col3\" >0.8299</td>\n",
       "      <td id=\"T_b4b13_row0_col4\" class=\"data row0 col4\" >0.8334</td>\n",
       "      <td id=\"T_b4b13_row0_col5\" class=\"data row0 col5\" >0.8316</td>\n",
       "      <td id=\"T_b4b13_row0_col6\" class=\"data row0 col6\" >0.7943</td>\n",
       "      <td id=\"T_b4b13_row0_col7\" class=\"data row0 col7\" >0.7943</td>\n",
       "      <td id=\"T_b4b13_row0_col8\" class=\"data row0 col8\" >15.1580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b13_level0_row1\" class=\"row_heading level0 row1\" >catboost</th>\n",
       "      <td id=\"T_b4b13_row1_col0\" class=\"data row1 col0\" >CatBoost Classifier</td>\n",
       "      <td id=\"T_b4b13_row1_col1\" class=\"data row1 col1\" >0.9376</td>\n",
       "      <td id=\"T_b4b13_row1_col2\" class=\"data row1 col2\" >0.9741</td>\n",
       "      <td id=\"T_b4b13_row1_col3\" class=\"data row1 col3\" >0.8144</td>\n",
       "      <td id=\"T_b4b13_row1_col4\" class=\"data row1 col4\" >0.8375</td>\n",
       "      <td id=\"T_b4b13_row1_col5\" class=\"data row1 col5\" >0.8258</td>\n",
       "      <td id=\"T_b4b13_row1_col6\" class=\"data row1 col6\" >0.7877</td>\n",
       "      <td id=\"T_b4b13_row1_col7\" class=\"data row1 col7\" >0.7879</td>\n",
       "      <td id=\"T_b4b13_row1_col8\" class=\"data row1 col8\" >66.6270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b13_level0_row2\" class=\"row_heading level0 row2\" >lr</th>\n",
       "      <td id=\"T_b4b13_row2_col0\" class=\"data row2 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_b4b13_row2_col1\" class=\"data row2 col1\" >0.9371</td>\n",
       "      <td id=\"T_b4b13_row2_col2\" class=\"data row2 col2\" >0.9719</td>\n",
       "      <td id=\"T_b4b13_row2_col3\" class=\"data row2 col3\" >0.8248</td>\n",
       "      <td id=\"T_b4b13_row2_col4\" class=\"data row2 col4\" >0.8283</td>\n",
       "      <td id=\"T_b4b13_row2_col5\" class=\"data row2 col5\" >0.8265</td>\n",
       "      <td id=\"T_b4b13_row2_col6\" class=\"data row2 col6\" >0.7881</td>\n",
       "      <td id=\"T_b4b13_row2_col7\" class=\"data row2 col7\" >0.7881</td>\n",
       "      <td id=\"T_b4b13_row2_col8\" class=\"data row2 col8\" >20.8860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b13_level0_row3\" class=\"row_heading level0 row3\" >xgboost</th>\n",
       "      <td id=\"T_b4b13_row3_col0\" class=\"data row3 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_b4b13_row3_col1\" class=\"data row3 col1\" >0.9367</td>\n",
       "      <td id=\"T_b4b13_row3_col2\" class=\"data row3 col2\" >0.9725</td>\n",
       "      <td id=\"T_b4b13_row3_col3\" class=\"data row3 col3\" >0.8187</td>\n",
       "      <td id=\"T_b4b13_row3_col4\" class=\"data row3 col4\" >0.8305</td>\n",
       "      <td id=\"T_b4b13_row3_col5\" class=\"data row3 col5\" >0.8245</td>\n",
       "      <td id=\"T_b4b13_row3_col6\" class=\"data row3 col6\" >0.7859</td>\n",
       "      <td id=\"T_b4b13_row3_col7\" class=\"data row3 col7\" >0.7860</td>\n",
       "      <td id=\"T_b4b13_row3_col8\" class=\"data row3 col8\" >14.5220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b13_level0_row4\" class=\"row_heading level0 row4\" >gbc</th>\n",
       "      <td id=\"T_b4b13_row4_col0\" class=\"data row4 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_b4b13_row4_col1\" class=\"data row4 col1\" >0.9366</td>\n",
       "      <td id=\"T_b4b13_row4_col2\" class=\"data row4 col2\" >0.9740</td>\n",
       "      <td id=\"T_b4b13_row4_col3\" class=\"data row4 col3\" >0.8466</td>\n",
       "      <td id=\"T_b4b13_row4_col4\" class=\"data row4 col4\" >0.8125</td>\n",
       "      <td id=\"T_b4b13_row4_col5\" class=\"data row4 col5\" >0.8292</td>\n",
       "      <td id=\"T_b4b13_row4_col6\" class=\"data row4 col6\" >0.7903</td>\n",
       "      <td id=\"T_b4b13_row4_col7\" class=\"data row4 col7\" >0.7906</td>\n",
       "      <td id=\"T_b4b13_row4_col8\" class=\"data row4 col8\" >75.9050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b13_level0_row5\" class=\"row_heading level0 row5\" >rf</th>\n",
       "      <td id=\"T_b4b13_row5_col0\" class=\"data row5 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_b4b13_row5_col1\" class=\"data row5 col1\" >0.9343</td>\n",
       "      <td id=\"T_b4b13_row5_col2\" class=\"data row5 col2\" >0.9691</td>\n",
       "      <td id=\"T_b4b13_row5_col3\" class=\"data row5 col3\" >0.8138</td>\n",
       "      <td id=\"T_b4b13_row5_col4\" class=\"data row5 col4\" >0.8227</td>\n",
       "      <td id=\"T_b4b13_row5_col5\" class=\"data row5 col5\" >0.8182</td>\n",
       "      <td id=\"T_b4b13_row5_col6\" class=\"data row5 col6\" >0.7781</td>\n",
       "      <td id=\"T_b4b13_row5_col7\" class=\"data row5 col7\" >0.7782</td>\n",
       "      <td id=\"T_b4b13_row5_col8\" class=\"data row5 col8\" >19.3360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b13_level0_row6\" class=\"row_heading level0 row6\" >et</th>\n",
       "      <td id=\"T_b4b13_row6_col0\" class=\"data row6 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_b4b13_row6_col1\" class=\"data row6 col1\" >0.9318</td>\n",
       "      <td id=\"T_b4b13_row6_col2\" class=\"data row6 col2\" >0.9659</td>\n",
       "      <td id=\"T_b4b13_row6_col3\" class=\"data row6 col3\" >0.7999</td>\n",
       "      <td id=\"T_b4b13_row6_col4\" class=\"data row6 col4\" >0.8204</td>\n",
       "      <td id=\"T_b4b13_row6_col5\" class=\"data row6 col5\" >0.8100</td>\n",
       "      <td id=\"T_b4b13_row6_col6\" class=\"data row6 col6\" >0.7684</td>\n",
       "      <td id=\"T_b4b13_row6_col7\" class=\"data row6 col7\" >0.7686</td>\n",
       "      <td id=\"T_b4b13_row6_col8\" class=\"data row6 col8\" >18.3610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b13_level0_row7\" class=\"row_heading level0 row7\" >lda</th>\n",
       "      <td id=\"T_b4b13_row7_col0\" class=\"data row7 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_b4b13_row7_col1\" class=\"data row7 col1\" >0.9310</td>\n",
       "      <td id=\"T_b4b13_row7_col2\" class=\"data row7 col2\" >0.9692</td>\n",
       "      <td id=\"T_b4b13_row7_col3\" class=\"data row7 col3\" >0.8246</td>\n",
       "      <td id=\"T_b4b13_row7_col4\" class=\"data row7 col4\" >0.8015</td>\n",
       "      <td id=\"T_b4b13_row7_col5\" class=\"data row7 col5\" >0.8128</td>\n",
       "      <td id=\"T_b4b13_row7_col6\" class=\"data row7 col6\" >0.7706</td>\n",
       "      <td id=\"T_b4b13_row7_col7\" class=\"data row7 col7\" >0.7707</td>\n",
       "      <td id=\"T_b4b13_row7_col8\" class=\"data row7 col8\" >14.5310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b13_level0_row8\" class=\"row_heading level0 row8\" >ada</th>\n",
       "      <td id=\"T_b4b13_row8_col0\" class=\"data row8 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_b4b13_row8_col1\" class=\"data row8 col1\" >0.9303</td>\n",
       "      <td id=\"T_b4b13_row8_col2\" class=\"data row8 col2\" >0.9714</td>\n",
       "      <td id=\"T_b4b13_row8_col3\" class=\"data row8 col3\" >0.8541</td>\n",
       "      <td id=\"T_b4b13_row8_col4\" class=\"data row8 col4\" >0.7824</td>\n",
       "      <td id=\"T_b4b13_row8_col5\" class=\"data row8 col5\" >0.8166</td>\n",
       "      <td id=\"T_b4b13_row8_col6\" class=\"data row8 col6\" >0.7737</td>\n",
       "      <td id=\"T_b4b13_row8_col7\" class=\"data row8 col7\" >0.7749</td>\n",
       "      <td id=\"T_b4b13_row8_col8\" class=\"data row8 col8\" >23.9910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b13_level0_row9\" class=\"row_heading level0 row9\" >ridge</th>\n",
       "      <td id=\"T_b4b13_row9_col0\" class=\"data row9 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_b4b13_row9_col1\" class=\"data row9 col1\" >0.9301</td>\n",
       "      <td id=\"T_b4b13_row9_col2\" class=\"data row9 col2\" >0.0000</td>\n",
       "      <td id=\"T_b4b13_row9_col3\" class=\"data row9 col3\" >0.8236</td>\n",
       "      <td id=\"T_b4b13_row9_col4\" class=\"data row9 col4\" >0.7982</td>\n",
       "      <td id=\"T_b4b13_row9_col5\" class=\"data row9 col5\" >0.8106</td>\n",
       "      <td id=\"T_b4b13_row9_col6\" class=\"data row9 col6\" >0.7678</td>\n",
       "      <td id=\"T_b4b13_row9_col7\" class=\"data row9 col7\" >0.7680</td>\n",
       "      <td id=\"T_b4b13_row9_col8\" class=\"data row9 col8\" >10.5190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b13_level0_row10\" class=\"row_heading level0 row10\" >svm</th>\n",
       "      <td id=\"T_b4b13_row10_col0\" class=\"data row10 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_b4b13_row10_col1\" class=\"data row10 col1\" >0.9283</td>\n",
       "      <td id=\"T_b4b13_row10_col2\" class=\"data row10 col2\" >0.0000</td>\n",
       "      <td id=\"T_b4b13_row10_col3\" class=\"data row10 col3\" >0.8023</td>\n",
       "      <td id=\"T_b4b13_row10_col4\" class=\"data row10 col4\" >0.8032</td>\n",
       "      <td id=\"T_b4b13_row10_col5\" class=\"data row10 col5\" >0.8027</td>\n",
       "      <td id=\"T_b4b13_row10_col6\" class=\"data row10 col6\" >0.7589</td>\n",
       "      <td id=\"T_b4b13_row10_col7\" class=\"data row10 col7\" >0.7590</td>\n",
       "      <td id=\"T_b4b13_row10_col8\" class=\"data row10 col8\" >11.5360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b13_level0_row11\" class=\"row_heading level0 row11\" >knn</th>\n",
       "      <td id=\"T_b4b13_row11_col0\" class=\"data row11 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_b4b13_row11_col1\" class=\"data row11 col1\" >0.9163</td>\n",
       "      <td id=\"T_b4b13_row11_col2\" class=\"data row11 col2\" >0.9255</td>\n",
       "      <td id=\"T_b4b13_row11_col3\" class=\"data row11 col3\" >0.7947</td>\n",
       "      <td id=\"T_b4b13_row11_col4\" class=\"data row11 col4\" >0.7569</td>\n",
       "      <td id=\"T_b4b13_row11_col5\" class=\"data row11 col5\" >0.7753</td>\n",
       "      <td id=\"T_b4b13_row11_col6\" class=\"data row11 col6\" >0.7239</td>\n",
       "      <td id=\"T_b4b13_row11_col7\" class=\"data row11 col7\" >0.7243</td>\n",
       "      <td id=\"T_b4b13_row11_col8\" class=\"data row11 col8\" >24.7030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b13_level0_row12\" class=\"row_heading level0 row12\" >dt</th>\n",
       "      <td id=\"T_b4b13_row12_col0\" class=\"data row12 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_b4b13_row12_col1\" class=\"data row12 col1\" >0.9016</td>\n",
       "      <td id=\"T_b4b13_row12_col2\" class=\"data row12 col2\" >0.8418</td>\n",
       "      <td id=\"T_b4b13_row12_col3\" class=\"data row12 col3\" >0.7478</td>\n",
       "      <td id=\"T_b4b13_row12_col4\" class=\"data row12 col4\" >0.7209</td>\n",
       "      <td id=\"T_b4b13_row12_col5\" class=\"data row12 col5\" >0.7341</td>\n",
       "      <td id=\"T_b4b13_row12_col6\" class=\"data row12 col6\" >0.6737</td>\n",
       "      <td id=\"T_b4b13_row12_col7\" class=\"data row12 col7\" >0.6739</td>\n",
       "      <td id=\"T_b4b13_row12_col8\" class=\"data row12 col8\" >14.5720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b13_level0_row13\" class=\"row_heading level0 row13\" >nb</th>\n",
       "      <td id=\"T_b4b13_row13_col0\" class=\"data row13 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_b4b13_row13_col1\" class=\"data row13 col1\" >0.8206</td>\n",
       "      <td id=\"T_b4b13_row13_col2\" class=\"data row13 col2\" >0.8751</td>\n",
       "      <td id=\"T_b4b13_row13_col3\" class=\"data row13 col3\" >0.8191</td>\n",
       "      <td id=\"T_b4b13_row13_col4\" class=\"data row13 col4\" >0.5039</td>\n",
       "      <td id=\"T_b4b13_row13_col5\" class=\"data row13 col5\" >0.6239</td>\n",
       "      <td id=\"T_b4b13_row13_col6\" class=\"data row13 col6\" >0.5148</td>\n",
       "      <td id=\"T_b4b13_row13_col7\" class=\"data row13 col7\" >0.5410</td>\n",
       "      <td id=\"T_b4b13_row13_col8\" class=\"data row13 col8\" >10.3840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b13_level0_row14\" class=\"row_heading level0 row14\" >dummy</th>\n",
       "      <td id=\"T_b4b13_row14_col0\" class=\"data row14 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_b4b13_row14_col1\" class=\"data row14 col1\" >0.8183</td>\n",
       "      <td id=\"T_b4b13_row14_col2\" class=\"data row14 col2\" >0.5000</td>\n",
       "      <td id=\"T_b4b13_row14_col3\" class=\"data row14 col3\" >0.0000</td>\n",
       "      <td id=\"T_b4b13_row14_col4\" class=\"data row14 col4\" >0.0000</td>\n",
       "      <td id=\"T_b4b13_row14_col5\" class=\"data row14 col5\" >0.0000</td>\n",
       "      <td id=\"T_b4b13_row14_col6\" class=\"data row14 col6\" >0.0000</td>\n",
       "      <td id=\"T_b4b13_row14_col7\" class=\"data row14 col7\" >0.0000</td>\n",
       "      <td id=\"T_b4b13_row14_col8\" class=\"data row14 col8\" >9.9470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b13_level0_row15\" class=\"row_heading level0 row15\" >qda</th>\n",
       "      <td id=\"T_b4b13_row15_col0\" class=\"data row15 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_b4b13_row15_col1\" class=\"data row15 col1\" >0.7915</td>\n",
       "      <td id=\"T_b4b13_row15_col2\" class=\"data row15 col2\" >0.7363</td>\n",
       "      <td id=\"T_b4b13_row15_col3\" class=\"data row15 col3\" >0.4965</td>\n",
       "      <td id=\"T_b4b13_row15_col4\" class=\"data row15 col4\" >0.4762</td>\n",
       "      <td id=\"T_b4b13_row15_col5\" class=\"data row15 col5\" >0.4625</td>\n",
       "      <td id=\"T_b4b13_row15_col6\" class=\"data row15 col6\" >0.3392</td>\n",
       "      <td id=\"T_b4b13_row15_col7\" class=\"data row15 col7\" >0.3518</td>\n",
       "      <td id=\"T_b4b13_row15_col8\" class=\"data row15 col8\" >13.4380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x3d21a7750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14536a0eb688433388dae13b728ef0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top10 = gemini_experiment.compare_models(n_select=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the models are performing a little better than the default PyCaret AutoML model! Now let's ask Gemini to ensemble the models and see if we can get a better score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_models = gemini_experiment.pull()\n",
    "\n",
    "Top10Models = enum.Enum(\"Top10Models\", {model: model for model in top10_models})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlendModelsSchema(TypedDict):\n",
    "    models_to_ensemble: List[Top10Models]  # type: ignore\n",
    "    should_tune: bool\n",
    "    blend_weights: NotRequired[List[float]]\n",
    "\n",
    "\n",
    "result = chat.send_message(\n",
    "    textwrap.dedent(\n",
    "        f\"\"\"\n",
    "        Here are the top 10 models based on the comparison. Let's decide on the blending models parameters for the data.\n",
    "        \n",
    "        {top10_models.to_markdown()}\n",
    "                \n",
    "        Remember that performing a binary classification to predict depression target variable based on various features.\n",
    "        \n",
    "        Generate the following parameters for blending models in PyCaret for final prediction:\n",
    "\n",
    "        * models_to_ensemble: A list of the model names to ensemble for blending. You can choose any number of models from the top 10 models. It should be a list of model names.\n",
    "        * should_tune: A boolean value indicating whether to tune the hyperparameters of the blending model. If true, the hyperparameters will be tuned.\n",
    "        * blend_weights: A list of float values specifying the weights of each model in the blending ensemble. This parameter is optional. If it is not provided, the models will be blended with equal weights. Otherwise, the length of the list should be equal to the number of models in the ensemble denoted by `models_to_ensemble`. The total of the weights should ALWAYS sum up to 1.\n",
    "        \n",
    "\n",
    "        All parameters are required.\n",
    "\n",
    "        **Example JSON Response:**\n",
    "\n",
    "        ```json\n",
    "        {{\n",
    "            models_to_ensemble: [\"lightgbm\", \"lt\"],\n",
    "            should_tune: true,\n",
    "            blend_weights: [0.25, 0.75]\n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        \"\"\"\n",
    "    ),\n",
    "    generation_config=genai.GenerationConfig(\n",
    "        response_schema=get_dict_schema(BlendModelsSchema),\n",
    "        response_mime_type=\"application/json\",\n",
    "    ),\n",
    "    request_options=retry_policy,\n",
    ")\n",
    "\n",
    "blender_parameters = json.loads(result.text)\n",
    "print(blender_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_model = gemini_experiment.blend_models(\n",
    "    estimator_list=blender_parameters[\"models_to_ensemble\"],\n",
    "    weights=blender_parameters.get(\"blend_weights\", None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if blender_parameters[\"should_tune\"]:\n",
    "    blending_tuned_model = gemini_experiment.tune_model(blended_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackModelsSchema(TypedDict):\n",
    "    models_to_ensemble: List[Top10Models]  # type: ignore\n",
    "    should_tune: bool\n",
    "    stack_weights: NotRequired[List[float]]\n",
    "\n",
    "\n",
    "result = chat.send_message(\n",
    "    textwrap.dedent(\n",
    "        f\"\"\"\n",
    "        Here are the top 10 models based on the comparison. Let's decide on the stacking model parameters for the data.\n",
    "        \n",
    "        {top10_models.to_markdown()}\n",
    "                \n",
    "        Remember that performing a binary classification to predict depression target variable based on various features.\n",
    "        \n",
    "        Generate the following parameters for stacking models in PyCaret for final prediction:\n",
    "\n",
    "        * models_to_ensemble: A list of the model names to ensemble for stacking ensemble. You can choose any number of models from the top 10 models. It should be a list of model names.\n",
    "        * should_tune: A boolean value indicating whether to tune the hyperparameters of the stacking model. If true, the hyperparameters will be tuned.\n",
    "        * blend_weights: A list of float values specifying the weights of each model in the stacking ensemble. This parameter is optional. If it is not provided, the models will be blended with equal weights. Otherwise, the length of the list should be equal to the number of models in the ensemble denoted by `models_to_ensemble`. The total of the weights should ALWAYS sum up to 1.\n",
    "        \n",
    "\n",
    "        All parameters are required.\n",
    "\n",
    "        **Example JSON Response:**\n",
    "\n",
    "        ```json\n",
    "        {{\n",
    "            models_to_ensemble: [\"lt\", \"catboost\"],\n",
    "            should_tune: true,\n",
    "            blend_weights: [0.25, 0.75]\n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        \"\"\"\n",
    "    ),\n",
    "    generation_config=genai.GenerationConfig(\n",
    "        response_schema=get_dict_schema(StackModelsSchema),\n",
    "        response_mime_type=\"application/json\",\n",
    "    ),\n",
    "    request_options=retry_policy,\n",
    ")\n",
    "\n",
    "stacker_parameters = json.loads(result.text)\n",
    "print(stacker_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model = gemini_experiment.stack_models(\n",
    "    estimator_list=stacker_parameters[\"models_to_ensemble\"],\n",
    "    weights=stacker_parameters.get(\"blend_weights\", None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if blender_parameters[\"should_tune\"]:\n",
    "    stacking_tuned_model = gemini_experiment.tune_model(stacking_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the ensemble model is performing better than the individual models. Let's submit the predictions to the Kaggle competition and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = gemini_experiment.predict_model(stacking_tuned_model, data=test_df)\n",
    "submission.to_csv(\"./gemini_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The PyCaret AutoML model tuned by Gemini gave me a accuracy of 0.94167 on the test set. This was better than the PyCaret AutoML model with default settings. This pushed me to 1314 rank on the public leaderboard (out of 2313 submissions), which is in the top 57 percentile. This is a slight improvement over the default PyCaret AutoML model.\n",
    "\n",
    "I'm seriously impressed by the capabilities of Gemini. It was able to understand the dataset and give me the best parameters for setting up the PyCaret AutoML experiment. It was also able to suggest the best ensemble model and helped me to get a better score on the Kaggle competition.\n",
    "\n",
    "## What's next?\n",
    "\n",
    "I did not use some more of the advanced features that Gemini and Langchain provides\n",
    "* Function calling - https://ai.google.dev/gemini-api/docs/function-calling\n",
    "* Agents - https://langchain-ai.github.io/langgraph/\n",
    "\n",
    "I also did not experiment with more parameters for setting up the PyCaret AutoML experiment. I'm sure with more experiments, Gemini will probably score better on the Kaggle competition.\n",
    "\n",
    "I'm sure with improved prompting, and some more experiments, Gemini get a better score on the Kaggle competition. I'm excited to see how it performs on the other Kaggle competition that I'm interested in."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
